{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LATAM Challenge Data Engineer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DescripciÃ³n del caso\n",
    "\n",
    "El ejercicio de estudio del desafio corresponde al anÃ¡lisis de datos provenientes desde Twitter, actualmente 'X', en donde se busca rescatar informaciÃ³n estadistica de los tweets relacionados a las protestas en India de sus granjeros. Estos anÃ¡lisis estan enfocados en dos grandes metricas, la utilizaciÃ³n de memoria y tiempo de cada uno de las funciones que buscan entregar respuesta a las preguntas planteadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Supuestos y consideraciones\n",
    "\n",
    "Se realizo una revisiÃ³n inicial a los datos proporcionados, revisando la existencia de tweets duplicados, o si existen mÃ¡s de una mensiÃ³n a la misma persona en el mismo tweets de la siguiente manera:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import jsonlines\n",
    "\n",
    "data = []\n",
    "file_path = \"../data/farmers-protest-tweets-2021-2-4.json\"\n",
    "with jsonlines.open(file_path) as reader:\n",
    "    for obj in reader:\n",
    "        users = []\n",
    "        users_dedup = []\n",
    "        mentioned_users = obj.get('mentionedUsers', {})\n",
    "        if mentioned_users:\n",
    "            users.extend([item['username'] for item in mentioned_users])\n",
    "            users_dedup.extend(list(set(item['username'] for item in mentioned_users)))\n",
    "        tweet = {\n",
    "            'date': obj.get('date'),\n",
    "            'id': obj.get('id'),\n",
    "            'username': obj.get('user', {}).get('username'),\n",
    "            'mentionedUsers': users,\n",
    "            'users_dedup': users_dedup\n",
    "        }\n",
    "        data.append(tweet)\n",
    "df = pl.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_count = df.group_by('id').len()\n",
    "id_count = id_count.filter(pl.col('len')>1)\n",
    "len(id_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El total de registros duplicados para el dataframe por el id del tweet generado es cero para el archivo de estudio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la revisiÃ³n de las multiples mensiones en el mismo tweets se veficÃ³ de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mensiones_duplicadas = df.filter(pl.col('mentionedUsers').len() != pl.col('users_dedup').len())\n",
    "len(mensiones_duplicadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supuestos generales\n",
    "\n",
    "1. Los archivos para su ejecuciÃ³n se encuentran en la ruta: \"../data/farmers-protest-tweets-2021-2-4.json\"\n",
    "2. Los emojis con variaciones de tono de piel serÃ¡n tratados como emojis distintos.\n",
    "3. Los datos que se extraen desde Twitter son unicos y no tienen duplicados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ExplicaciÃ³n de las funciones implementadas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1\n",
    "Las top 10 fechas donde hay mÃ¡s tweets. Mencionar el usuario (username) que mÃ¡s publicaciones tiene por cada uno de esos dÃ­as."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OptimizaciÃ³n de Tiempo\n",
    "\n",
    "Para responder a este requerimiento se optÃ³ por utilizar la libreria *polars* de python, con la cual se busca cargar la informaciÃ³n a procesar en memoria para posteriormente procesarla segÃºn las necesidades del caso.\n",
    "\n",
    "```\n",
    "with jsonlines.open(file_path) as reader:\n",
    "        for obj in reader:\n",
    "            # Se rescata solo los campos que se analizaran\n",
    "            filter_obj = {\n",
    "                'date': obj.get('date'),\n",
    "                'username': obj.get('user', {}).get('username')\n",
    "            }\n",
    "            data.append(filter_obj)\n",
    "```\n",
    "\n",
    "De la estructura de cada objeto json se obtiene la fecha y el username del usuario que realizo el tweet.\n",
    "\n",
    "Luego se procesa con polars, primero para obtener las fechas con mÃ¡s tweets\n",
    "\n",
    "```\n",
    "    top_fechas =( df\n",
    "                    .group_by('date')\n",
    "                    .len()\n",
    "                    .sort('len',descending=True)\n",
    "                    .head(10)['date']\n",
    "                )\n",
    "```\n",
    "\n",
    "Luego se filtra el dataframe inicial por estas fechas\n",
    "\n",
    "```\n",
    "result = (  df_filtrado.group_by(['date', 'username'])\n",
    "            .len() # Se cuenta para cada usuario por fecha \n",
    "            .sort(by=['date', 'len'], descending=[False, True]) # Se ordena por fecha desendente false y largo true\n",
    "            .group_by('date') # se agrupa por fechas\n",
    "            .agg(\n",
    "                    # Se agrega y se rescata le primer usuario por fecha\n",
    "                    pl.col('username').first()\n",
    "                )\n",
    "     )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "from q1_time import q1_time\n",
    "result = q1_time(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OptimizaciÃ³n de Memoria\n",
    "\n",
    "Para responder a este requerimiento se optÃ³ por la lectura secuencial del archivo, por cada linea nueva que se procesa se rescatan las estadisticas necesarias para el cÃ¡lculo final.\n",
    "\n",
    "```\n",
    "with jsonlines.open(file_path) as reader:\n",
    "    for obj in reader:\n",
    "        # Se obtiene la fecha de cada uno de los registros\n",
    "        fecha_str = obj.get('date')[:10]\n",
    "        # Se castea de string a datetime.date\n",
    "        fecha = datetime.strptime(fecha_str, '%Y-%m-%d').date()\n",
    "        # Se actualiza el contador de fechas\n",
    "        fecha_counter[fecha] += 1\n",
    "        # Se actualiza el contador de usuarios por fechas\n",
    "        fecha_usuario_counter[fecha][obj.get('user', {}).get('username')] += 1\n",
    "```\n",
    "\n",
    "Se utiliza un  `fecha_usuario_counter = defaultdict(Counter)` para almacenar los totales por cada fecha y usuario.\n",
    "\n",
    "Luego se itera por cada una de las fechas.\n",
    "\n",
    "```\n",
    "for fecha in top_fechas:\n",
    "    usuarios = fecha_usuario_counter[fecha[0]]\n",
    "    usuario_mas_repetido = usuarios.most_common(1)[0][0]\n",
    "    result.append((fecha[0], usuario_mas_repetido))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "from q1_memory import q1_memory\n",
    "result = q1_memory(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ComparaciÃ³n de tiempo y uso de memoria para cada una de las funciones\n",
    "#### Tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4391046240000005"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from io import StringIO\n",
    "from q1_time import q1_time\n",
    "from q1_memory import q1_memory\n",
    "\n",
    "output_stream = StringIO()\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "q1_time(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "stats = pstats.Stats(profiler)\n",
    "stats.stream = output_stream\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('time')\n",
    "stats.print_stats()\n",
    "\n",
    "# Obtener el tottime final\n",
    "tiempo_total_q1_time = stats.total_tt\n",
    "tiempo_total_q1_time\n",
    "\n",
    "output_stream = StringIO()\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "q1_memory(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "stats = pstats.Stats(profiler)\n",
    "stats.stream = output_stream\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('time')\n",
    "stats.print_stats()\n",
    "# Obtener el tottime final\n",
    "tiempo_total_q1_memory = stats.total_tt\n",
    "tiempo_total_q1_memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La funcion que prioriza el tiempo tiene un consumo de: 2.4391 segundos, \n",
      "mientras que la funcion que prioriza el uso de memoria tiene un consumo de: 3.1812 segundos\n",
      "Lo que representra una mejora de 30.4233%\n"
     ]
    }
   ],
   "source": [
    "print(f'La funcion que prioriza el tiempo tiene un consumo de: {tiempo_total_q1_time:.4f} segundos, \\nmientras que la funcion que prioriza el uso de memoria tiene un consumo de: {tiempo_total_q1_memory:.4f} segundos')\n",
    "diferencia_porcentual = (abs(tiempo_total_q1_memory - tiempo_total_q1_time) / tiempo_total_q1_time) * 100\n",
    "print(f'Lo que representra una mejora de {diferencia_porcentual:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/hvera/Dev/DE_LATAM_challenge/LATAM-Data-Engineer-Challenge/src/q1_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     6     96.1 MiB     96.1 MiB           1   def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "     7                                             \"\"\"\n",
      "     8                                             Funcion que lee un archivo JSONL y encuentra las 10 fechas con mayor cantidad de tweets, para cada una de estas fechas entrega el usuario con mayor cantidad de tweets.\n",
      "     9                                             \n",
      "    10                                             Args:\n",
      "    11                                                 file_path (str): Ruta del archivo JSONL que contiene los tweets para analizar.\n",
      "    12                                             \n",
      "    13                                             Returns:\n",
      "    14                                                 List[Tuple[datetime.date, str]]: Lista de tuplas, donde el primer elemento corresponde a la fecha y el segundo elemento al nombre del usuario.\n",
      "    15                                             \"\"\"\n",
      "    16     96.1 MiB      0.0 MiB           1       result = []\n",
      "    17                                             # Contador para las fechas\n",
      "    18     96.1 MiB      0.0 MiB           1       fecha_counter = Counter()\n",
      "    19     96.1 MiB      0.0 MiB           1       fecha_usuario_counter = defaultdict(Counter)\n",
      "    20                                             # Lectura de archivo JSONL, se lee linea por linea para para reducir el uso de memoria\n",
      "    21     96.2 MiB      0.0 MiB           1       with jsonlines.open(file_path) as reader:\n",
      "    22     98.3 MiB -10890.4 MiB      117408           for obj in reader:\n",
      "    23                                                     # Se obtiene la fecha de cada uno de los registros\n",
      "    24     98.3 MiB -10890.2 MiB      117407               fecha_str = obj.get('date')[:10]\n",
      "    25                                                     # Se castea de string a datetime.date\n",
      "    26     98.3 MiB -10891.3 MiB      117407               fecha = datetime.strptime(fecha_str, '%Y-%m-%d').date()\n",
      "    27                                                     # Se actualiza el contador de fechas\n",
      "    28     98.3 MiB -10891.4 MiB      117407               fecha_counter[fecha] += 1\n",
      "    29                                                     # Se actualiza el contador de usuarios por fechas\n",
      "    30     98.3 MiB -10889.9 MiB      117407               fecha_usuario_counter[fecha][obj.get('user', {}).get('username')] += 1\n",
      "    31                                             \n",
      "    32                                             # El top 10 de elementos mas comunes del contador\n",
      "    33     97.3 MiB     -0.9 MiB           1       top_fechas = fecha_counter.most_common(10)\n",
      "    34                                             # Se itera por cada una de las fechas con mayor cantidad de tweets\n",
      "    35     97.4 MiB      0.0 MiB          11       for fecha in top_fechas:\n",
      "    36     97.4 MiB      0.0 MiB          10           usuarios = fecha_usuario_counter[fecha[0]]\n",
      "    37     97.4 MiB      0.0 MiB          10           usuario_mas_repetido = usuarios.most_common(1)[0][0]\n",
      "    38     97.4 MiB      0.0 MiB          10           result.append((fecha[0], usuario_mas_repetido))    \n",
      "    39                                             \n",
      "    40     97.4 MiB      0.0 MiB           1       return result"
     ]
    }
   ],
   "source": [
    "%reload_ext memory_profiler\n",
    "%mprun -f q1_memory q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/hvera/Dev/DE_LATAM_challenge/LATAM-Data-Engineer-Challenge/src/q1_time.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     6     97.1 MiB     97.1 MiB           1   def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "     7                                             \"\"\"\n",
      "     8                                             Funcion que lee un archivo JSONL y encuentra las 10 fechas con mayor cantidad de tweets, para cada una de estas fechas entrega el usuario con mayor cantidad de tweets, se prioriza el tiempo de ejecucion.\n",
      "     9                                             Para esto se carga toda la informacion en memoria antes de procesarla.\n",
      "    10                                             Args:\n",
      "    11                                                 file_path (str): Ruta del archivo JSONL que contiene los tweets para analizar.\n",
      "    12                                             \n",
      "    13                                             Returns:\n",
      "    14                                                 List[Tuple[datetime.date, str]]: Lista de tuplas, donde el primer elemento corresponde a la fecha y el segundo elemento al nombre del usuario.\n",
      "    15                                             \"\"\"\n",
      "    16                                             # Lista que almacena la informacion en memoria linea por linea\n",
      "    17     97.1 MiB      0.0 MiB           1       data = []\n",
      "    18                                             # Lectura de archivo JSONL, se lee linea por linea\n",
      "    19     97.2 MiB      0.0 MiB           1       with jsonlines.open(file_path) as reader:\n",
      "    20    135.4 MiB  -1369.9 MiB      117408           for obj in reader:\n",
      "    21                                                     # Se rescata solo los campos que se analizaran\n",
      "    22    135.3 MiB  -1408.2 MiB      117407               filter_obj = {\n",
      "    23    135.3 MiB  -1407.6 MiB      117407                   'date': obj.get('date'),\n",
      "    24    135.3 MiB  -1407.7 MiB      117407                   'username': obj.get('user', {}).get('username')\n",
      "    25                                                     }\n",
      "    26    135.3 MiB  -1408.0 MiB      117407               data.append(filter_obj)\n",
      "    27                                             # creacion de dataframe\n",
      "    28    162.5 MiB     27.1 MiB           1       df = pl.DataFrame(data)\n",
      "    29                                             # Transformacion de la columna date de str a date\n",
      "    30    164.7 MiB      2.3 MiB           1       df = df.with_columns([pl.col('date').str.strptime(pl.Date, \"%Y-%m-%dT%H:%M:%S%z\").alias('date')])\n",
      "    31                                             \n",
      "    32                                             # Se retornan las 10 fechas con mayor cantidad de tweets\n",
      "    33    169.4 MiB      4.6 MiB           5       top_fechas =( df\n",
      "    34    164.8 MiB      0.0 MiB           1                       .group_by('date')\n",
      "    35                                                             .len()\n",
      "    36    169.2 MiB      0.0 MiB           1                       .sort('len',descending=True)\n",
      "    37    169.2 MiB      0.0 MiB           2                       .head(10)['date']\n",
      "    38                                                         )\n",
      "    39                                             # Se filtra el dataset por estas fechas\n",
      "    40    172.6 MiB      3.3 MiB           1       df_filtrado = df.filter(pl.col('date').is_in(top_fechas))\n",
      "    41                                             # Se elimina el dataset original\n",
      "    42    172.6 MiB      0.0 MiB           1       del df\n",
      "    43                                             # Se procesa el dataset filtrado\n",
      "    44    181.8 MiB      9.1 MiB           4       result = (  df_filtrado.group_by(['date', 'username'])\n",
      "    45                                                     .len() # Se cuenta para cada usuario por fecha \n",
      "    46    180.5 MiB      0.0 MiB           1               .sort(by=['date', 'len'], descending=[False, True]) # Se ordena por fecha desendente false y largo true\n",
      "    47    181.5 MiB      0.0 MiB           1               .group_by('date') # se agrupa por fechas\n",
      "    48                                                     .agg(\n",
      "    49                                                             # Se agrega y se rescata le primer usuario por fecha\n",
      "    50    181.6 MiB      0.0 MiB           1                       pl.col('username').first()\n",
      "    51                                                         )\n",
      "    52                                              )\n",
      "    53                                             # El resultado se joinea con las fechas para mantener el orden original\n",
      "    54                                             # que consiste en las fechas con mas tweets\n",
      "    55    182.5 MiB      0.7 MiB           1       result = top_fechas.to_frame().join(result, on='date',how=\"left\")\n",
      "    56                                             # Se formatea el output para que sea consistente con la descripcion de la funcion\n",
      "    57    182.5 MiB      0.1 MiB          13       result = [tuple(row.values()) for row in result.to_dicts()]\n",
      "    58    182.5 MiB      0.0 MiB           1       return result"
     ]
    }
   ],
   "source": [
    "%reload_ext memory_profiler\n",
    "%mprun -f q1_time q1_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "q1_memory.py    26.4 MiB\n",
    "q1_time.py      100.0 MiB\n",
    "q2_memory.py    26.2 MiB\n",
    "q2_time.py      1660.4 MiB\n",
    "q3_memory.py    22.3 MiB\n",
    "q3_time.py      64.1 MiB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "Los top 10 emojis mÃ¡s usados con su respectivo conteo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OptimizaciÃ³n de Tiempo\n",
    "\n",
    "Para responder a este requerimiento se optÃ³ por utilizar la libreria *pandas* de python, a diferencia del resto de implementaciones se cargo todo el archivo en memoria para luego procesarlo.\n",
    "\n",
    "`df = pd.read_json(file_path, lines=True)`\n",
    "\n",
    "Luego utilizando la libreria *emot* se utiliza su implementaciÃ³n para la lectura con multiprocesador en la siguiente linea:\n",
    "\n",
    "`emojis = emot_obj.bulk_emoji(data)`\n",
    "\n",
    "Para luego continuar con el procesamiento y terminar contando con *Counter*.\n",
    "\n",
    "Como mejoras a este ejercicio se propone identificar emojis con cambio de tono de piel como un solo emoji, por ejemplo: ðŸ‘ðŸ½ y ðŸ‘, sean tratados como un solo emoji y no dos como esta en la implementaciÃ³n actual.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ðŸ™', 5049), ('ðŸ˜‚', 3072), ('ðŸšœ', 2972), ('ðŸŒ¾', 2182), ('ðŸ‡®ðŸ‡³', 2086), ('â¤', 1779), ('ðŸ¤£', 1668), ('âœŠ', 1651), ('ðŸ™ðŸ»', 1317), ('ðŸ’š', 1040)]\n"
     ]
    }
   ],
   "source": [
    "from q2_time import q2_time\n",
    "result = q2_time(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OptimizaciÃ³n de Memoria\n",
    "\n",
    "Para responder a este requerimiento se optÃ³ por la lectura secuencial del archivo utilizando la libreria *jsonlines*.\n",
    "\n",
    "`with jsonlines.open(file_path) as reader`\n",
    "\n",
    "Por cada una de las lineas procesadas se utiliza el metodo *emoji* que retorna un diccionario con los emojis y su ubicaciÃ³n en el texto.\n",
    "\n",
    "`emojis = emot_obj.emoji(content)`\n",
    "\n",
    "Ejemplo de salida:\n",
    "\n",
    "` {'value': ['â˜®', 'ðŸ™‚', 'â¤'], 'location': [[14, 15], [16, 17], [18, 19]], 'mean': [':peace_symbol:',':slightly_smiling_face:', ':red_heart:'], 'flag': True}` \n",
    "\n",
    "De este resultado se utilza 'value' el que se agrega al contador\n",
    "\n",
    "`emojis = [item for item in emojis['value']]`\n",
    "\n",
    "`contador.update(emojis)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ðŸ™', 5049), ('ðŸ˜‚', 3072), ('ðŸšœ', 2972), ('ðŸŒ¾', 2182), ('ðŸ‡®ðŸ‡³', 2086), ('â¤', 1779), ('ðŸ¤£', 1668), ('âœŠ', 1651), ('ðŸ™ðŸ»', 1317), ('ðŸ’š', 1040)]\n"
     ]
    }
   ],
   "source": [
    "from q2_memory import q2_memory\n",
    "result = q2_memory(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ComparaciÃ³n de tiempo y uso de memoria para cada una de las funciones\n",
    "#### Tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from io import StringIO\n",
    "from q2_time import q2_time\n",
    "from q2_memory import q2_memory\n",
    "\n",
    "output_stream = StringIO()\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "q2_time(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "stats = pstats.Stats(profiler)\n",
    "stats.stream = output_stream\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('time')\n",
    "stats.print_stats()\n",
    "\n",
    "# Obtener el tottime final\n",
    "tiempo_total_q2_time = stats.total_tt\n",
    "\n",
    "output_stream = StringIO()\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "q2_memory(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "stats = pstats.Stats(profiler)\n",
    "stats.stream = output_stream\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('time')\n",
    "stats.print_stats()\n",
    "# Obtener el tottime final\n",
    "tiempo_total_q2_memory = stats.total_tt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La funcion que prioriza el tiempo tiene un consumo de: 10.1644 segundos, \n",
      "mientras que la funcion que prioriza el uso de memoria tiene un consumo de: 19.8816 segundos\n",
      "Lo que representra una mejora de 95.6000%\n"
     ]
    }
   ],
   "source": [
    "print(f'La funcion que prioriza el tiempo tiene un consumo de: {tiempo_total_q2_time:.4f} segundos, \\nmientras que la funcion que prioriza el uso de memoria tiene un consumo de: {tiempo_total_q2_memory:.4f} segundos')\n",
    "diferencia_porcentual = (abs(tiempo_total_q2_memory - tiempo_total_q2_time) / tiempo_total_q2_time) * 100\n",
    "print(f'Lo que representra una mejora de {diferencia_porcentual:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/hvera/Dev/DE_LATAM_challenge/LATAM-Data-Engineer-Challenge/src/q2_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     6    182.1 MiB    182.1 MiB           1   def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
      "     7                                             \"\"\"\n",
      "     8                                             Funcion que lee un archivo JSONL y encuentra los 10 emojis mas usados, priorizando el uso de memoria.\n",
      "     9                                             \n",
      "    10                                             Args:\n",
      "    11                                                 file_path (str): Ruta del archivo JSONL que contiene los tweets para analizar.\n",
      "    12                                             \n",
      "    13                                             Returns:\n",
      "    14                                                 List[Tuple[str, int]]: Lista de tuplas, donde el primer elemento corresponde al emoji y el segundo a la cantidad de veces que se utiliza.\n",
      "    15                                             \"\"\"\n",
      "    16                                             # Contador para los emojis\n",
      "    17    182.1 MiB      0.0 MiB           1       contador = Counter()\n",
      "    18                                             # Se genera un objeto emot.core.emot\n",
      "    19    183.6 MiB      1.5 MiB           1       emot_obj = emot.core.emot()\n",
      "    20                                             # Lectura de archivo JSONL, se lee linea por linea para para reducir el uso de memoria\n",
      "    21    183.6 MiB      0.0 MiB           1       with jsonlines.open(file_path) as reader:\n",
      "    22    183.9 MiB -17803.5 MiB      117408           for obj in reader:\n",
      "    23                                                     # Se obtiene el objeto content que es donde esta el cuerpo del tweet\n",
      "    24    183.9 MiB -17803.2 MiB      117407               content = obj.get('content')\n",
      "    25                                                     # Se obtiene la lista de diccionarios de los emojis encontrados en el texto\n",
      "    26    183.9 MiB -17803.4 MiB      117407               emojis = emot_obj.emoji(content)\n",
      "    27    183.9 MiB -17803.6 MiB      117407               if(emojis['value']):\n",
      "    28                                                         # Si se encontraron emojis en el texto se almacena solo los emojis\n",
      "    29    183.9 MiB -14560.1 MiB       93534                   emojis = [item for item in emojis['value']]\n",
      "    30                                                         # Se actualiza el contador con la lista de emojis\n",
      "    31    183.9 MiB  -2616.0 MiB       16869                   contador.update(emojis)\n",
      "    32                                             # Se retorna el top 10 de emojis\n",
      "    33    183.6 MiB     -0.3 MiB           1       return contador.most_common(10)"
     ]
    }
   ],
   "source": [
    "%reload_ext memory_profiler\n",
    "%mprun -f q2_memory q2_memory(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/hvera/Dev/DE_LATAM_challenge/LATAM-Data-Engineer-Challenge/src/q2_time.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     8    182.8 MiB    182.8 MiB           1   def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
      "     9                                             \"\"\"\n",
      "    10                                             Funcion que lee un archivo JSONL y encuentra los 10 emojis mas usados, priorizando el uso de memoria.\n",
      "    11                                         \n",
      "    12                                             Args:\n",
      "    13                                                 file_path (str): Ruta del archivo JSONL que contiene los tweets para analizar.\n",
      "    14                                         \n",
      "    15                                             Returns:\n",
      "    16                                                 List[Tuple[str, int]]: Lista de tuplas, donde el primer elemento corresponde al emoji y el segundo a la cantidad de veces que se utiliza.\n",
      "    17                                             \"\"\"\n",
      "    18                                             # Contador para los emojis\n",
      "    19    182.8 MiB      0.0 MiB           1       contador = Counter()\n",
      "    20                                             # Lectura de archivo JSONL, se carga todo en memoria con pandas\n",
      "    21   1857.6 MiB   1674.8 MiB           1       df = pd.read_json(file_path, lines=True)\n",
      "    22                                             # Se genera un objeto emot.core.emot\n",
      "    23   1858.8 MiB      1.2 MiB           1       emot_obj = emot.core.emot()\n",
      "    24                                             # Se genera una lista con todos los elementos del dataframe de la columna content\n",
      "    25                                             # Esta columna es la que tiene la informacion del texto del tweet\n",
      "    26   1858.8 MiB      0.0 MiB           1       data = df['content'].tolist()\n",
      "    27                                             # Se utiliza el metodo bulk_emoji ya que utiliza multi procesamiento\n",
      "    28   1901.8 MiB     43.0 MiB           1       emojis = emot_obj.bulk_emoji(data)\n",
      "    29                                             # Se deja la lista aplana la lista de listas solamente cuando existen emojis\n",
      "    30   1901.8 MiB      0.0 MiB      151149       emojis = list(chain.from_iterable(item['value']\n",
      "    31   1901.8 MiB      0.0 MiB      117408                     for item in emojis if item['value']))\n",
      "    32                                             # Actualizo el contador\n",
      "    33   1901.8 MiB      0.0 MiB           1       contador.update(emojis)\n",
      "    34   1901.8 MiB      0.0 MiB           1       return contador.most_common(10)"
     ]
    }
   ],
   "source": [
    "%reload_ext memory_profiler\n",
    "%mprun -f q2_time q2_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3\n",
    "El top 10 histÃ³rico de usuarios (username) mÃ¡s influyentes en funciÃ³n del conteo de las menciones (@) que registra cada uno de ellos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OptimizaciÃ³n de Tiempo\n",
    "\n",
    "Para responder a este requerimiento se utilizÃ³ la misma aproximaciÃ³n que para el ejercicio 1, en donde se lee el archivo linea por linea con *jsonlines* para de esta forma generar un consilidado de los usuarios mencionados.\n",
    "\n",
    "```\n",
    "with jsonlines.open(file_path) as reader:\n",
    "    for obj in reader:\n",
    "        mentioned_users = obj.get('mentionedUsers', {})\n",
    "        if mentioned_users:\n",
    "            data.extend([item['username'] for item in mentioned_users])\n",
    "```\n",
    "\n",
    "En la lista data se almacenan todos los usuarios que aparecen como menciones.\n",
    "Luego se genera un dataframe de *polars* para contar, ordernar y retornar los 10 elementos mÃ¡s comunes.\n",
    "\n",
    "```\n",
    "result = (df\n",
    "            .group_by('column_0') # se agrupa por la column_0, que es el username\n",
    "            .len() # Se cuentan los registros\n",
    "            .sort('len',descending=True) # Se ordenan de manera descendente\n",
    "            .head(10) # se retornan los 10 primeros registros\n",
    "   )\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n"
     ]
    }
   ],
   "source": [
    "from q3_time import q3_time\n",
    "result = q3_time(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OptimizaciÃ³n de Memoria\n",
    "\n",
    "Para responder a este requerimiento se optÃ³ por la lectura secuencial del archivo, al igual que la implementaciÃ³n del ejercicio 1 por cada linea nueva que se procesa se rescatan las estadisticas necesarias para el cÃ¡lculo final necesario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n"
     ]
    }
   ],
   "source": [
    "from q3_memory import q3_memory\n",
    "result = q3_memory(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ComparaciÃ³n de tiempo y uso de memoria para cada una de las funciones\n",
    "#### Tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from io import StringIO\n",
    "from q3_time import q3_time\n",
    "from q3_memory import q3_memory\n",
    "\n",
    "output_stream = StringIO()\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "q3_time(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "stats = pstats.Stats(profiler)\n",
    "stats.stream = output_stream\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('time')\n",
    "stats.print_stats()\n",
    "\n",
    "# Obtener el tottime final\n",
    "tiempo_total_q3_time = stats.total_tt\n",
    "\n",
    "output_stream = StringIO()\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "q3_memory(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "stats = pstats.Stats(profiler)\n",
    "stats.stream = output_stream\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('time')\n",
    "stats.print_stats()\n",
    "# Obtener el tottime final\n",
    "tiempo_total_q3_memory = stats.total_tt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La funcion que prioriza el tiempo tiene un consumo de: 2.3327 segundos, \n",
      "mientras que la funcion que prioriza el uso de memoria tiene un consumo de: 2.3663 segundos\n",
      "Lo que representra una mejora de 1.4403%\n"
     ]
    }
   ],
   "source": [
    "print(f'La funcion que prioriza el tiempo tiene un consumo de: {tiempo_total_q3_time:.4f} segundos, \\nmientras que la funcion que prioriza el uso de memoria tiene un consumo de: {tiempo_total_q3_memory:.4f} segundos')\n",
    "diferencia_porcentual = (abs(tiempo_total_q3_memory - tiempo_total_q3_time) / tiempo_total_q3_time) * 100\n",
    "print(f'Lo que representra una mejora de {diferencia_porcentual:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/hvera/Dev/DE_LATAM_challenge/LATAM-Data-Engineer-Challenge/src/q3_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     5    509.6 MiB    509.6 MiB           1   def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
      "     6                                             \"\"\"\n",
      "     7                                             Funcion que lee un archivo JSONL y encuentra los 10 usuarios con mayor numero de menciones.\n",
      "     8                                             \n",
      "     9                                             Args:\n",
      "    10                                                 file_path (str): Ruta del archivo JSONL que contiene los tweets para analizar.\n",
      "    11                                             \n",
      "    12                                             Returns:\n",
      "    13                                                 List[Tuple[str, int]]: Lista de tuplas, donde el primer elemento corresponde al nombre de usuario y el segundo a la cantidad de menciones.\n",
      "    14                                             \"\"\"\n",
      "    15                                             # Contador para los usuarios\n",
      "    16    509.6 MiB      0.0 MiB           1       contador = Counter()\n",
      "    17                                             # Lectura de archivo JSONL, se lee linea por linea para para reducir el uso de memoria\n",
      "    18    509.6 MiB      0.0 MiB           1       with jsonlines.open(file_path) as reader:\n",
      "    19    509.6 MiB      0.0 MiB      117408           for obj in reader:\n",
      "    20                                                     # Se rescata solo el campo mentionedUsers\n",
      "    21    509.6 MiB      0.0 MiB      117407               mentioned_users = obj.get('mentionedUsers', {})\n",
      "    22    509.6 MiB      0.0 MiB      117407               if mentioned_users:\n",
      "    23                                                         # Si existen usuarios mencionados rescato la lista de username\n",
      "    24    509.6 MiB      0.0 MiB      217505                   mentioned_users = [item['username'] for item in mentioned_users]\n",
      "    25                                                         # Actualizo con contador de usuarios\n",
      "    26    509.6 MiB      0.0 MiB       38034                   contador.update(mentioned_users)\n",
      "    27    509.6 MiB      0.0 MiB           1       return contador.most_common(10)"
     ]
    }
   ],
   "source": [
    "%reload_ext memory_profiler\n",
    "%mprun -f q3_memory q3_memory(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/hvera/Dev/DE_LATAM_challenge/LATAM-Data-Engineer-Challenge/src/q3_time.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     5    508.6 MiB    508.6 MiB           1   def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
      "     6                                             \"\"\"\n",
      "     7                                             Funcion que lee un archivo JSONL y encuentra los 10 usuarios con mayor numero de menciones, prioriza el tiempo de ejecucion.\n",
      "     8                                             \n",
      "     9                                             Args:\n",
      "    10                                                 file_path (str): Ruta del archivo JSONL que contiene los tweets para analizar.\n",
      "    11                                             \n",
      "    12                                             Returns:\n",
      "    13                                                 List[Tuple[str, int]]: Lista de tuplas, donde el primer elemento corresponde al nombre de usuario y el segundo a la cantidad de menciones.\n",
      "    14                                             \"\"\"\n",
      "    15                                         \n",
      "    16                                             # Lista que almacena la informacion en memoria linea por linea\n",
      "    17    508.6 MiB      0.0 MiB           1       data = []\n",
      "    18    508.6 MiB      0.0 MiB           1       result = []\n",
      "    19                                             # Lectura de archivo JSONL, se lee linea por linea\n",
      "    20    508.6 MiB      0.0 MiB           1       with jsonlines.open(file_path) as reader:\n",
      "    21    508.7 MiB      0.0 MiB      117408           for obj in reader:\n",
      "    22                                                     # Se rescata solo el campo mentionedUsers\n",
      "    23    508.7 MiB      0.0 MiB      117407               mentioned_users = obj.get('mentionedUsers', {})\n",
      "    24                                                     # Si se tienen mensiones en el tweet\n",
      "    25    508.7 MiB      0.0 MiB      117407               if mentioned_users:\n",
      "    26                                                         # Se extraen todos los usuarios mensionados\n",
      "    27    508.7 MiB      0.0 MiB      217505                   data.extend([item['username'] for item in mentioned_users])\n",
      "    28                                             # Creacion de dataframe\n",
      "    29    512.9 MiB      4.2 MiB           1       df = pl.DataFrame(data)\n",
      "    30                                             # Analisis del dataframe\n",
      "    31    523.9 MiB     11.1 MiB           4       result = (df\n",
      "    32    512.9 MiB      0.0 MiB           1                   .group_by('column_0') # se agrupa por la column_0, que es el username\n",
      "    33                                                         .len() # Se cuentan los registros\n",
      "    34    523.0 MiB      0.0 MiB           1                   .sort('len',descending=True) # Se ordenan de manera descendente\n",
      "    35    523.9 MiB      0.0 MiB           1                   .head(10) # se retornan los 10 primeros registros\n",
      "    36                                             )\n",
      "    37                                             # Se formatea el output para que sea consistente con la descripcion de la funcion\n",
      "    38    524.1 MiB      0.1 MiB          13       result = [tuple(row.values()) for row in result.to_dicts()]\n",
      "    39    524.1 MiB      0.0 MiB           1       return result"
     ]
    }
   ],
   "source": [
    "%reload_ext memory_profiler\n",
    "%mprun -f q3_time q3_time(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
