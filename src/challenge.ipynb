{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LATAM Challenge Data Engineer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Descripción del caso\n",
    "\n",
    "El ejercicio de estudio del desafío consiste en el análisis de datos provenientes de Twitter, actualmente X. El objetivo es rescatar información estadística de los tweets relacionados con las protestas de los granjeros en India. Este análisis están enfocados en dos métricas: la utilización de memoria y el tiempo de cada una de las funciones que buscan responder a las preguntas planteadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Supuestos y consideraciones\n",
    "\n",
    "Se realizó una revisión inicial de los datos proporcionados para identificar la existencia de tweets duplicados o de aquellos en los que existe más de una mención a la misma persona en el mismo tweet de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga inicial del archivo, los archivos siempre estaran en la ruta \"../data/<archivo>.json\"\n",
    "file_path = \"../data/farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import jsonlines\n",
    "\n",
    "data = []\n",
    "with jsonlines.open(file_path) as reader:\n",
    "    for obj in reader:\n",
    "        users = []\n",
    "        users_dedup = []\n",
    "        mentioned_users = obj.get('mentionedUsers', {})\n",
    "        if mentioned_users:\n",
    "            users.extend([item['username'] for item in mentioned_users])\n",
    "            users_dedup.extend(list(set(item['username'] for item in mentioned_users)))\n",
    "        tweet = {\n",
    "            'date': obj.get('date'),\n",
    "            'id': obj.get('id'),\n",
    "            'username': obj.get('user', {}).get('username'),\n",
    "            'mentionedUsers': users,\n",
    "            'users_dedup': users_dedup\n",
    "        }\n",
    "        data.append(tweet)\n",
    "df = pl.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_count = df.group_by('id').len()\n",
    "id_count = id_count.filter(pl.col('len')>1)\n",
    "len(id_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El total de registros duplicados para el dataframe por el id del tweet generado es cero para el archivo de estudio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La revisión de las múltiples menciones en el mismo tweet se verificó de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mensiones_duplicadas = df.filter(pl.col('mentionedUsers').len() != pl.col('users_dedup').len())\n",
    "len(mensiones_duplicadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supuestos generales\n",
    "\n",
    "1. Los archivos para su ejecución se encuentran en la ruta: \"../data/farmers-protest-tweets-2021-2-4.json\"\n",
    "2. Los emojis con variaciones de tono de piel serán tratados como emojis distintos.\n",
    "3. Los datos que se extraen desde Twitter son únicos y no tienen duplicados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explicación de las funciones implementadas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1\n",
    "Las top 10 fechas donde hay más tweets. Mencionar el usuario (username) que más publicaciones tiene por cada uno de esos días."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimización de tiempo\n",
    "\n",
    "Para responder a este requerimiento se optó por utilizar la librería *polars* de python, con la cual se busca cargar la información a procesar en memoria para posteriormente procesarla según las necesidades del caso.\n",
    "\n",
    "```Python\n",
    "with jsonlines.open(file_path) as reader:\n",
    "        for obj in reader:\n",
    "            # Se rescata solo los campos que se analizaran\n",
    "            filter_obj = {\n",
    "                'date': obj.get('date'),\n",
    "                'username': obj.get('user', {}).get('username')\n",
    "            }\n",
    "            data.append(filter_obj)\n",
    "```\n",
    "\n",
    "De la estructura de cada objeto json se obtiene la fecha y el username de quién realizó el tweet.\n",
    "\n",
    "Luego se procesa con polars, primero para obtener las fechas con más tweets:\n",
    "\n",
    "```Python\n",
    "    top_fechas =( df\n",
    "                    .group_by('date')\n",
    "                    .len()\n",
    "                    .sort('len',descending=True)\n",
    "                    .head(10)['date']\n",
    "                )\n",
    "```\n",
    "\n",
    "Luego se filtra el dataframe inicial por estas fechas:\n",
    "\n",
    "```Python\n",
    "result = (  df_filtrado.group_by(['date', 'username'])\n",
    "            .len() # Se cuenta para cada usuario por fecha \n",
    "            .sort(by=['date', 'len'], descending=[False, True]) # Se ordena por fecha desendente false y largo true\n",
    "            .group_by('date') # se agrupa por fechas\n",
    "            .agg(\n",
    "                    # Se agrega y se rescata le primer usuario por fecha\n",
    "                    pl.col('username').first()\n",
    "                )\n",
    "     )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "from q1_time import q1_time\n",
    "result = q1_time(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimización de memoria\n",
    "\n",
    "Para responder a este requerimiento se optó por la lectura secuencial del archivo, por cada linea nueva que se procesa se rescatan las estadísticas necesarias para el cálculo final.\n",
    "\n",
    "```Python\n",
    "with jsonlines.open(file_path) as reader:\n",
    "    for obj in reader:\n",
    "        # Se obtiene la fecha de cada uno de los registros\n",
    "        fecha_str = obj.get('date')[:10]\n",
    "        # Se castea de string a datetime.date\n",
    "        fecha = datetime.strptime(fecha_str, '%Y-%m-%d').date()\n",
    "        # Se actualiza el contador de fechas\n",
    "        fecha_counter[fecha] += 1\n",
    "        # Se actualiza el contador de usuarios por fechas\n",
    "        fecha_usuario_counter[fecha][obj.get('user', {}).get('username')] += 1\n",
    "```\n",
    "\n",
    "Se utiliza un  `fecha_usuario_counter = defaultdict(Counter)` para almacenar los totales por cada fecha y usuario.\n",
    "\n",
    "Luego se itera por cada una de las fechas.\n",
    "\n",
    "```Python\n",
    "for fecha in top_fechas:\n",
    "    usuarios = fecha_usuario_counter[fecha[0]]\n",
    "    usuario_mas_repetido = usuarios.most_common(1)[0][0]\n",
    "    result.append((fecha[0], usuario_mas_repetido))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "from q1_memory import q1_memory\n",
    "result = q1_memory(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de tiempo y uso de memoria para cada una de las funciones\n",
    "#### Tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.199416044"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from io import StringIO\n",
    "from q1_time import q1_time\n",
    "from q1_memory import q1_memory\n",
    "\n",
    "output_stream = StringIO()\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "q1_time(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "stats = pstats.Stats(profiler)\n",
    "stats.stream = output_stream\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('time')\n",
    "stats.print_stats()\n",
    "\n",
    "# Obtener el tottime final\n",
    "tiempo_total_q1_time = stats.total_tt\n",
    "tiempo_total_q1_time\n",
    "\n",
    "output_stream = StringIO()\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "q1_memory(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "stats = pstats.Stats(profiler)\n",
    "stats.stream = output_stream\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('time')\n",
    "stats.print_stats()\n",
    "# Obtener el tottime final\n",
    "tiempo_total_q1_memory = stats.total_tt\n",
    "tiempo_total_q1_memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La función que prioriza el tiempo tiene un consumo de: 2.4117 segundos, \n",
      "mientras que la función que prioriza el uso de memoria tiene un consumo de: 3.1994 segundos.\n",
      "Lo que representa una mejora de 28.0789%.\n"
     ]
    }
   ],
   "source": [
    "print(f'La función que prioriza el tiempo tiene un consumo de: {tiempo_total_q1_time:.4f} segundos, \\nmientras que la función que prioriza el uso de memoria tiene un consumo de: {tiempo_total_q1_memory:.4f} segundos.')\n",
    "diferencia_porcentual = (abs(tiempo_total_q1_time - tiempo_total_q1_memory)/((tiempo_total_q1_time + tiempo_total_q1_memory)/2)) * 100\n",
    "print(f'Lo que representa una mejora de {diferencia_porcentual:.4f}%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/hvera/Dev/DE_LATAM_challenge/LATAM-Data-Engineer-Challenge/src/q1_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     8    326.0 MiB    326.0 MiB           1   def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "     9                                             \"\"\"\n",
      "    10                                             Funcion que lee un archivo JSONL y encuentra las 10 fechas con mayor \n",
      "    11                                             cantidad de tweets, para cada una de estas fechas entrega el usuario \n",
      "    12                                             con mayor cantidad de tweets.\n",
      "    13                                         \n",
      "    14                                             Args:\n",
      "    15                                                 file_path (str): Ruta del archivo JSONL que contiene los tweets para \n",
      "    16                                                 analizar.\n",
      "    17                                         \n",
      "    18                                             Returns:\n",
      "    19                                                 List[Tuple[datetime.date, str]]: Lista de tuplas, donde el primer \n",
      "    20                                                 elemento corresponde a la fecha y el segundo elemento al nombre del \n",
      "    21                                                 usuario.\n",
      "    22                                             \"\"\"\n",
      "    23    326.0 MiB      0.0 MiB           1       result = []\n",
      "    24                                             # Contador para las fechas\n",
      "    25    326.0 MiB      0.0 MiB           1       fecha_counter = Counter()\n",
      "    26    326.0 MiB      0.0 MiB           1       fecha_usuario_counter = defaultdict(Counter)\n",
      "    27                                             # Lectura de archivo JSONL, se lee linea por linea para para reducir el uso\n",
      "    28                                             # de memoria\n",
      "    29    326.0 MiB      0.0 MiB           1       with jsonlines.open(file_path) as reader:\n",
      "    30    326.6 MiB      0.1 MiB      117408           for obj in reader:\n",
      "    31                                                     # Se obtiene la fecha de cada uno de los registros\n",
      "    32    326.6 MiB      0.0 MiB      117407               fecha_str = obj.get('date')[:10]\n",
      "    33                                                     # Se castea de string a datetime.date\n",
      "    34    326.6 MiB      0.0 MiB      117407               fecha = datetime.strptime(fecha_str, '%Y-%m-%d').date()\n",
      "    35                                                     # Se actualiza el contador de fechas\n",
      "    36    326.6 MiB      0.0 MiB      117407               fecha_counter[fecha] += 1\n",
      "    37                                                     # Se actualiza el contador de usuarios por fechas\n",
      "    38    326.6 MiB      0.5 MiB      469628               fecha_usuario_counter[fecha][obj.get(\n",
      "    39    326.6 MiB      0.0 MiB      352221                   'user', {}).get('username')] += 1\n",
      "    40                                         \n",
      "    41                                             # El top 10 de elementos mas comunes del contador\n",
      "    42    326.6 MiB      0.0 MiB           1       top_fechas = fecha_counter.most_common(10)\n",
      "    43                                             # Se itera por cada una de las fechas con mayor cantidad de tweets\n",
      "    44    326.6 MiB      0.0 MiB          11       for fecha in top_fechas:\n",
      "    45    326.6 MiB      0.0 MiB          10           usuarios = fecha_usuario_counter[fecha[0]]\n",
      "    46    326.6 MiB      0.0 MiB          10           usuario_mas_repetido = usuarios.most_common(1)[0][0]\n",
      "    47    326.6 MiB      0.0 MiB          10           result.append((fecha[0], usuario_mas_repetido))\n",
      "    48                                         \n",
      "    49    326.6 MiB      0.0 MiB           1       return result"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "%mprun -f q1_memory q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total de memoria utilizada  326.6 MiB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/hvera/Dev/DE_LATAM_challenge/LATAM-Data-Engineer-Challenge/src/q1_time.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     8    326.6 MiB    326.6 MiB           1   def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "     9                                             \"\"\"\n",
      "    10                                             Funcion que lee un archivo JSONL y encuentra las 10 fechas con mayor \n",
      "    11                                             cantidad de tweets, para cada una de estas fechas entrega el usuario con \n",
      "    12                                             mayor cantidad de tweets, se prioriza el tiempo de ejecucion.\n",
      "    13                                             Para esto se carga toda la informacion en memoria antes de procesarla.\n",
      "    14                                         \n",
      "    15                                             Args:\n",
      "    16                                                 file_path (str): Ruta del archivo JSONL que contiene los tweets para \n",
      "    17                                                 analizar.\n",
      "    18                                         \n",
      "    19                                             Returns:\n",
      "    20                                                 List[Tuple[datetime.date, str]]: Lista de tuplas, donde el primer \n",
      "    21                                                 elemento corresponde a la fecha y el segundo elemento al nombre del \n",
      "    22                                                 usuario.\n",
      "    23                                             \"\"\"\n",
      "    24                                             # Lista que almacena la informacion en memoria linea por linea\n",
      "    25    326.6 MiB      0.0 MiB           1       data = []\n",
      "    26                                             # Lectura de archivo JSONL, se lee linea por linea\n",
      "    27    326.6 MiB      0.0 MiB           1       with jsonlines.open(file_path) as reader:\n",
      "    28    366.8 MiB     39.6 MiB      117408           for obj in reader:\n",
      "    29                                                     # Se rescata solo los campos que se analizaran\n",
      "    30    366.8 MiB      0.0 MiB      117407               filter_obj = {\n",
      "    31    366.8 MiB      0.0 MiB      117407                   'date': obj.get('date'),\n",
      "    32    366.8 MiB      0.0 MiB      117407                   'username': obj.get('user', {}).get('username')\n",
      "    33                                                     }\n",
      "    34    366.8 MiB      0.6 MiB      117407               data.append(filter_obj)\n",
      "    35                                             # creacion de dataframe\n",
      "    36    366.8 MiB      0.0 MiB           1       df = pl.DataFrame(data)\n",
      "    37                                             # Transformacion de la columna date de str a date\n",
      "    38    366.8 MiB      0.0 MiB           3       df = df.with_columns([pl.col('date').str.strptime(\n",
      "    39    366.8 MiB      0.0 MiB           2           pl.Date, \"%Y-%m-%dT%H:%M:%S%z\").alias('date')])\n",
      "    40                                         \n",
      "    41                                             # Se retornan las 10 fechas con mayor cantidad de tweets\n",
      "    42    366.8 MiB      0.0 MiB           5       top_fechas = (df\n",
      "    43    366.8 MiB      0.0 MiB           1                     .group_by('date')\n",
      "    44                                                           .len()\n",
      "    45    366.8 MiB      0.0 MiB           1                     .sort('len', descending=True)\n",
      "    46    366.8 MiB      0.0 MiB           2                     .head(10)['date']\n",
      "    47                                                           )\n",
      "    48                                             # Se filtra el dataset por estas fechas\n",
      "    49    366.8 MiB      0.0 MiB           1       df_filtrado = df.filter(pl.col('date').is_in(top_fechas))\n",
      "    50                                             # Se elimina el dataset original\n",
      "    51    366.8 MiB      0.0 MiB           1       del df\n",
      "    52                                             # Se procesa el dataset filtrado\n",
      "    53    368.4 MiB      1.6 MiB           4       result = (df_filtrado.group_by(['date', 'username'])\n",
      "    54                                                       .len()  # Se cuenta para cada usuario por fecha\n",
      "    55                                                       # Se ordena por fecha desendente false y largo true\n",
      "    56    367.7 MiB      0.0 MiB           1                 .sort(by=['date', 'len'], descending=[False, True])\n",
      "    57    368.4 MiB      0.0 MiB           1                 .group_by('date')  # se agrupa por fechas\n",
      "    58                                                       .agg(\n",
      "    59                                                 # Se agrega y se rescata le primer usuario por fecha\n",
      "    60    368.4 MiB      0.0 MiB           1           pl.col('username').first()\n",
      "    61                                             )\n",
      "    62                                             )\n",
      "    63                                             # El resultado se joinea con las fechas para mantener el orden original\n",
      "    64                                             # que consiste en las fechas con mas tweets\n",
      "    65    368.4 MiB      0.0 MiB           1       result = top_fechas.to_frame().join(result, on='date', how=\"left\")\n",
      "    66                                             # Se formatea el output para que sea consistente con la descripcion de \n",
      "    67                                             # la funcion\n",
      "    68    368.4 MiB      0.0 MiB          13       result = [tuple(row.values()) for row in result.to_dicts()]\n",
      "    69    368.4 MiB      0.0 MiB           1       return result"
     ]
    }
   ],
   "source": [
    "%mprun -f q1_time q1_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total de memoria utilizada  368.4 MiB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "Los top 10 emojis más usados con su respectivo conteo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimización de tiempo\n",
    "\n",
    "Para responder a este requerimiento se optó por utilizar la librería *pandas* de python, a diferencia del resto de implementaciones se cargó todo el archivo en memoria para luego procesarlo.\n",
    "\n",
    "`df = pd.read_json(file_path, lines=True)`\n",
    "\n",
    "Luego utilizando la librería *emot* se utiliza su implementación para la lectura con multiprocesador en la siguiente línea:\n",
    "\n",
    "`emojis = emot_obj.bulk_emoji(data)`\n",
    "\n",
    "Para luego continuar con el procesamiento y terminar contando con *Counter*.\n",
    "\n",
    "Como mejoras a este ejercicio se propone identificar emojis con cambio de tono de piel como un solo emoji, por ejemplo: 👍🏽 y 👍, sean tratados como un solo emoji y no dos como está en la implementación actual.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('🙏', 5049), ('😂', 3072), ('🚜', 2972), ('🌾', 2182), ('🇮🇳', 2086), ('❤', 1779), ('🤣', 1668), ('✊', 1651), ('🙏🏻', 1317), ('💚', 1040)]\n"
     ]
    }
   ],
   "source": [
    "from q2_time import q2_time\n",
    "result = q2_time(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimización de memoria\n",
    "\n",
    "Para responder a este requerimiento se optó por la lectura secuencial del archivo utilizando la librería *jsonlines*.\n",
    "\n",
    "`with jsonlines.open(file_path) as reader`\n",
    "\n",
    "Por cada una de las lineas procesadas se utiliza el método *emoji* que retorna un diccionario con los emojis y su ubicación en el texto.\n",
    "\n",
    "`emojis = emot_obj.emoji(content)`\n",
    "\n",
    "Ejemplo de salida:\n",
    "\n",
    "` {'value': ['☮', '🙂', '❤'], 'location': [[14, 15], [16, 17], [18, 19]], 'mean': [':peace_symbol:',':slightly_smiling_face:', ':red_heart:'], 'flag': True}` \n",
    "\n",
    "De este resultado se utilza 'value' el que se agrega al contador:\n",
    "\n",
    "`emojis = [item for item in emojis['value']]`\n",
    "\n",
    "`contador.update(emojis)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('🙏', 5049), ('😂', 3072), ('🚜', 2972), ('🌾', 2182), ('🇮🇳', 2086), ('❤', 1779), ('🤣', 1668), ('✊', 1651), ('🙏🏻', 1317), ('💚', 1040)]\n"
     ]
    }
   ],
   "source": [
    "from q2_memory import q2_memory\n",
    "result = q2_memory(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de tiempo y uso de memoria para cada una de las funciones\n",
    "#### Tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from io import StringIO\n",
    "from q2_time import q2_time\n",
    "from q2_memory import q2_memory\n",
    "\n",
    "output_stream = StringIO()\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "q2_time(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "stats = pstats.Stats(profiler)\n",
    "stats.stream = output_stream\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('time')\n",
    "stats.print_stats()\n",
    "\n",
    "# Obtener el tottime final\n",
    "tiempo_total_q2_time = stats.total_tt\n",
    "\n",
    "output_stream = StringIO()\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "q2_memory(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "stats = pstats.Stats(profiler)\n",
    "stats.stream = output_stream\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('time')\n",
    "stats.print_stats()\n",
    "# Obtener el tottime final\n",
    "tiempo_total_q2_memory = stats.total_tt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La función que prioriza el tiempo tiene un consumo de: 8.3032 segundos, \n",
      "mientras que la función que prioriza el uso de memoria tiene un consumo de: 19.6812 segundos.\n",
      "Lo que representa una mejora de 81.3168%.\n"
     ]
    }
   ],
   "source": [
    "print(f'La función que prioriza el tiempo tiene un consumo de: {tiempo_total_q2_time:.4f} segundos, \\nmientras que la función que prioriza el uso de memoria tiene un consumo de: {tiempo_total_q2_memory:.4f} segundos.')\n",
    "diferencia_porcentual = (abs(tiempo_total_q2_time - tiempo_total_q2_memory)/((tiempo_total_q2_time + tiempo_total_q2_memory)/2)) * 100\n",
    "print(f'Lo que representa una mejora de {diferencia_porcentual:.4f}%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/hvera/Dev/DE_LATAM_challenge/LATAM-Data-Engineer-Challenge/src/q2_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     8    532.2 MiB    532.2 MiB           1   def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
      "     9                                             \"\"\"\n",
      "    10                                             Funcion que lee un archivo JSONL y encuentra los 10 emojis mas usados, \n",
      "    11                                             priorizando el uso de memoria.\n",
      "    12                                         \n",
      "    13                                             Args:\n",
      "    14                                                 file_path (str): Ruta del archivo JSONL que contiene los tweets para\n",
      "    15                                                 analizar.\n",
      "    16                                         \n",
      "    17                                             Returns:\n",
      "    18                                                 List[Tuple[str, int]]: Lista de tuplas, donde el primer elemento \n",
      "    19                                                 corresponde al emoji y el segundo a la cantidad de veces que se utiliza.\n",
      "    20                                             \"\"\"\n",
      "    21                                             # Contador para los emojis\n",
      "    22    532.2 MiB      0.0 MiB           1       contador = Counter()\n",
      "    23                                             # Se genera un objeto emot.core.emot\n",
      "    24    532.0 MiB     -0.2 MiB           1       emot_obj = emot.core.emot()\n",
      "    25                                             # Lectura de archivo JSONL, se lee linea por linea para para reducir\n",
      "    26                                             # el uso de memoria\n",
      "    27    532.0 MiB      0.0 MiB           1       with jsonlines.open(file_path) as reader:\n",
      "    28    532.0 MiB      0.0 MiB      117408           for obj in reader:\n",
      "    29                                                     # Se obtiene el objeto content que es donde esta el cuerpo del tweet\n",
      "    30    532.0 MiB      0.0 MiB      117407               content = obj.get('content')\n",
      "    31                                                     # Se obtiene la lista de diccionarios de los emojis encontrados\n",
      "    32                                                     # en el texto\n",
      "    33    532.0 MiB      0.0 MiB      117407               emojis = emot_obj.emoji(content)\n",
      "    34    532.0 MiB      0.0 MiB      117407               if emojis['value']:\n",
      "    35                                                         # Si se encontraron emojis en el texto se almacena solo\n",
      "    36                                                         # los emojis\n",
      "    37    532.0 MiB      0.0 MiB       93534                   emojis = [item for item in emojis['value']]\n",
      "    38                                                         # Se actualiza el contador con la lista de emojis\n",
      "    39    532.0 MiB      0.0 MiB       16869                   contador.update(emojis)\n",
      "    40                                             # Se retorna el top 10 de emojis\n",
      "    41    532.0 MiB      0.0 MiB           1       return contador.most_common(10)"
     ]
    }
   ],
   "source": [
    "%mprun -f q2_memory q2_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total de memoria utilizada  532.0 MiB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/hvera/Dev/DE_LATAM_challenge/LATAM-Data-Engineer-Challenge/src/q2_time.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     9    532.0 MiB    532.0 MiB           1   def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
      "    10                                             \"\"\"\n",
      "    11                                             Funcion que lee un archivo JSONL y encuentra los 10 emojis mas usados, \n",
      "    12                                             priorizando el uso de memoria.\n",
      "    13                                         \n",
      "    14                                             Args:\n",
      "    15                                                 file_path (str): Ruta del archivo JSONL que contiene los tweets \n",
      "    16                                                 para analizar.\n",
      "    17                                         \n",
      "    18                                             Returns:\n",
      "    19                                                 List[Tuple[str, int]]: Lista de tuplas, donde el primer elemento \n",
      "    20                                                 corresponde al emoji y el segundo a la cantidad de veces que se utiliza.\n",
      "    21                                             \"\"\"\n",
      "    22                                             # Contador para los emojis\n",
      "    23    532.0 MiB      0.0 MiB           1       contador = Counter()\n",
      "    24                                             # Lectura de archivo JSONL, se carga todo en memoria con pandas\n",
      "    25   1967.3 MiB   1435.3 MiB           1       df = pd.read_json(file_path, lines=True)\n",
      "    26                                             # Se genera un objeto emot.core.emot\n",
      "    27   1967.3 MiB      0.0 MiB           1       emot_obj = emot.core.emot()\n",
      "    28                                             # Se genera una lista con todos los elementos del dataframe de la\n",
      "    29                                             # columna content.\n",
      "    30                                             # Esta columna es la que tiene la informacion del texto del tweet\n",
      "    31   1967.3 MiB      0.0 MiB           1       data = df['content'].tolist()\n",
      "    32                                             # Se utiliza el metodo bulk_emoji ya que utiliza multi procesamiento\n",
      "    33   2009.3 MiB     41.9 MiB           1       emojis = emot_obj.bulk_emoji(data)\n",
      "    34                                             # Se deja la lista aplana la lista de listas solamente cuando existen emojis\n",
      "    35   2009.3 MiB      0.0 MiB      151149       emojis = list(chain.from_iterable(item['value']\n",
      "    36   2009.3 MiB      0.0 MiB      117408                     for item in emojis if item['value']))\n",
      "    37                                             # Actualizo el contador\n",
      "    38   2009.3 MiB      0.0 MiB           1       contador.update(emojis)\n",
      "    39   2009.3 MiB      0.0 MiB           1       return contador.most_common(10)"
     ]
    }
   ],
   "source": [
    "%mprun -f q2_time q2_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total de memoria utilizada  2009.3 MiB. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3\n",
    "El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimización de tiempo\n",
    "\n",
    "Para responder a este requerimiento se probaron varias formas: para la primera prueba se utilizó la misma aproximación aplicada al ejercicio 1, con la combinación de *polars* y *jsonlines*. Al momento de comparar esta solución con aquella que optimiza memoria, no siempre se obtuvieron mejores resultados en cuanto a tiempo.\n",
    "\n",
    "La segund aproximación para este ejercició se realizó con el uso de *pandas* y cargar el archivo completo en memoria para procesar la columna que tiene los usuarios mencionados. Esta solución entregó peores tiempos en comparación con la primera propuesta de solución, por lo que se descartó.\n",
    "\n",
    "La opción por la que finalmente se optó fue una mezcla entre la solución implementada para la optimización de memoria, con la diferencia que en esta se cargan todos los usuarios mencionados y luego se actualiza un contador.\n",
    "\n",
    "```Python\n",
    "with jsonlines.open(file_path) as reader:\n",
    "        for obj in reader:\n",
    "            # Se rescata solo el campo mentionedUsers\n",
    "            mentioned_users = obj.get('mentionedUsers', {})\n",
    "            # Si se tienen mensiones en el tweet\n",
    "            if mentioned_users:\n",
    "                # Se extraen todos los usuarios mensionados\n",
    "                data.extend([item['username'] for item in mentioned_users])\n",
    "    # Se actualiza el contador\n",
    "    contador.update(data)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n"
     ]
    }
   ],
   "source": [
    "from q3_time import q3_time\n",
    "result = q3_time(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimización de memoria\n",
    "\n",
    "Para responder a este requerimiento se optó por la lectura secuencial del archivo, al igual que en la implementación del ejercicio 1 por cada línea nueva que se procesa se rescatan las línea necesarias para el cálculo final.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n"
     ]
    }
   ],
   "source": [
    "from q3_memory import q3_memory\n",
    "result = q3_memory(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de tiempo y uso de memoria para cada una de las funciones\n",
    "#### Tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from io import StringIO\n",
    "from q3_time import q3_time\n",
    "from q3_memory import q3_memory\n",
    "\n",
    "output_stream = StringIO()\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "q3_time(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "stats = pstats.Stats(profiler)\n",
    "stats.stream = output_stream\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('time')\n",
    "stats.print_stats()\n",
    "\n",
    "# Obtener el tottime final\n",
    "tiempo_total_q3_time = stats.total_tt\n",
    "\n",
    "output_stream = StringIO()\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "q3_memory(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "stats = pstats.Stats(profiler)\n",
    "stats.stream = output_stream\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('time')\n",
    "stats.print_stats()\n",
    "# Obtener el tottime final\n",
    "tiempo_total_q3_memory = stats.total_tt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La función que prioriza el tiempo tiene un consumo de: 2.3312 segundos, \n",
      "mientras que la función que prioriza el uso de memoria tiene un consumo de: 2.3320 segundos.\n",
      "Lo que representra una mejora de 0.0345%.\n"
     ]
    }
   ],
   "source": [
    "print(f'La función que prioriza el tiempo tiene un consumo de: {tiempo_total_q3_time:.4f} segundos, \\nmientras que la función que prioriza el uso de memoria tiene un consumo de: {tiempo_total_q3_memory:.4f} segundos.')\n",
    "diferencia_porcentual = (abs(tiempo_total_q3_time - tiempo_total_q3_memory)/((tiempo_total_q3_time + tiempo_total_q3_memory)/2)) * 100\n",
    "print(f'Lo que representra una mejora de {diferencia_porcentual:.4f}%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/hvera/Dev/DE_LATAM_challenge/LATAM-Data-Engineer-Challenge/src/q3_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     7    528.4 MiB    528.4 MiB           1   def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
      "     8                                             \"\"\"\n",
      "     9                                             Funcion que lee un archivo JSONL y encuentra los 10 usuarios con mayor\n",
      "    10                                             numero de menciones.\n",
      "    11                                             \n",
      "    12                                             Args:\n",
      "    13                                                 file_path (str): Ruta del archivo JSONL que contiene los tweets \n",
      "    14                                                 para analizar.\n",
      "    15                                             \n",
      "    16                                             Returns:\n",
      "    17                                                 List[Tuple[str, int]]: Lista de tuplas, donde el primer elemento \n",
      "    18                                                 corresponde al nombre de usuario y el segundo a la cantidad de menciones.\n",
      "    19                                             \"\"\"\n",
      "    20                                             # Contador para los usuarios\n",
      "    21    528.4 MiB      0.0 MiB           1       contador = Counter()\n",
      "    22                                             # Lectura de archivo JSONL, se lee linea por linea para para reducir\n",
      "    23                                             # el uso de memoria\n",
      "    24    528.4 MiB      0.0 MiB           1       with jsonlines.open(file_path) as reader:\n",
      "    25    528.4 MiB      0.0 MiB      117408           for obj in reader:\n",
      "    26                                                     # Se rescata solo el campo mentionedUsers\n",
      "    27    528.4 MiB      0.0 MiB      117407               mentioned_users = obj.get('mentionedUsers', {})\n",
      "    28    528.4 MiB      0.0 MiB      117407               if mentioned_users:\n",
      "    29                                                         # Si existen usuarios mencionados rescato la lista de username\n",
      "    30    528.4 MiB      0.0 MiB      217505                   mentioned_users = [item['username'] for item in mentioned_users]\n",
      "    31                                                         # Actualizo con contador de usuarios\n",
      "    32    528.4 MiB      0.0 MiB       38034                   contador.update(mentioned_users)\n",
      "    33    528.4 MiB      0.0 MiB           1       return contador.most_common(10)"
     ]
    }
   ],
   "source": [
    "%mprun -f q3_memory q3_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total de memoria utilizada  528.4 MiB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/hvera/Dev/DE_LATAM_challenge/LATAM-Data-Engineer-Challenge/src/q3_time.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     7    528.4 MiB    528.4 MiB           1   def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
      "     8                                             \"\"\"\n",
      "     9                                             Funcion que lee un archivo JSONL y encuentra los 10 usuarios con mayor \n",
      "    10                                             numero de menciones, prioriza el tiempo de ejecucion.\n",
      "    11                                         \n",
      "    12                                             Args:\n",
      "    13                                                 file_path (str): Ruta del archivo JSONL que contiene los tweets \n",
      "    14                                                 para analizar.\n",
      "    15                                         \n",
      "    16                                             Returns:\n",
      "    17                                                 List[Tuple[str, int]]: Lista de tuplas, donde el primer \n",
      "    18                                                 elemento corresponde al nombre de usuario y el segundo a la cantidad \n",
      "    19                                                 de menciones.\n",
      "    20                                             \"\"\"\n",
      "    21                                         \n",
      "    22                                             # Lista que almacena la informacion en memoria linea por linea\n",
      "    23    528.4 MiB      0.0 MiB           1       data = []\n",
      "    24    528.4 MiB      0.0 MiB           1       contador = Counter()\n",
      "    25                                             # Lectura de archivo JSONL, se lee linea por linea\n",
      "    26    528.4 MiB      0.0 MiB           1       with jsonlines.open(file_path) as reader:\n",
      "    27    528.4 MiB      0.0 MiB      117408           for obj in reader:\n",
      "    28                                                     # Se rescata solo el campo mentionedUsers\n",
      "    29    528.4 MiB      0.0 MiB      117407               mentioned_users = obj.get('mentionedUsers', {})\n",
      "    30                                                     # Si se tienen mensiones en el tweet\n",
      "    31    528.4 MiB      0.0 MiB      117407               if mentioned_users:\n",
      "    32                                                         # Se extraen todos los usuarios mensionados\n",
      "    33    528.4 MiB      0.0 MiB      217505                   data.extend([item['username'] for item in mentioned_users])\n",
      "    34                                             # Se actualiza el contador\n",
      "    35    528.4 MiB      0.0 MiB           1       contador.update(data)\n",
      "    36    528.4 MiB      0.0 MiB           1       return contador.most_common(10)"
     ]
    }
   ],
   "source": [
    "%mprun -f q3_time q3_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total de memoria utilizada  528.4 MiB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notas Adicionales \n",
    "\n",
    "En pruebas realizadas fuera del contexto del notebook los resultados generales para cada una de las funciones implementadas son los siguientes:\n",
    "1. Ejercicio 1\n",
    "\n",
    "| Métrica   | q1_time       | q1_memory      | Diff %   |\n",
    "|-----------|---------------|--------------- |----------|\n",
    "| Time      | 2.401 seconds | 3.150 seconds  | 26.986       |\n",
    "| Memory    | 100.0 MiB     | 26.4 MiB      | 116.456       |\n",
    "\n",
    "\n",
    "2. Ejercicio 2\n",
    "\n",
    "| Métrica   | q2_time       | q2_memory      | Diff %|\n",
    "|-----------|---------------|----------------|---------|\n",
    "| Time      | 9.249 seconds | 19.624 seconds | 71.866      |\n",
    "| Memory    | 1660.4 MiB    | 26.2 MiB       | 193.786      |\n",
    "\n",
    "\n",
    "3. Ejercicio 3\n",
    "\n",
    "| Métrica   | q3_time       | q3_memory      | Diff %   |\n",
    "|-----------|---------------|--------------- |----------|\n",
    "| Time      | 2.257 seconds | 2.621 seconds  | 14.924       |\n",
    "| Memory    | 29.0 MiB      | 22.1 MiB       | 27.006      |\n",
    "\n",
    "\n",
    "## Mejoras\n",
    "\n",
    "Para las funciones que se desarrollaron se podrían realizar las siguientes mejoras:\n",
    "\n",
    "A. Al momento de cargar el archivo línea por línea, revisar si la línea que se está cargando corresponde a un objeto JSON.\n",
    "\n",
    "```Python\n",
    "with jsonlines.open(file_path) as reader:\n",
    "        for obj in reader:\n",
    "            # Se rescata solo el campo mentionedUsers\n",
    "            try:\n",
    "                mentioned_users = obj.get('mentionedUsers', {})\n",
    "            # Si se tienen mensiones en el tweet\n",
    "                if mentioned_users:\n",
    "                # Se extraen todos los usuarios mensionados\n",
    "                    data.extend([item['username'] for item in mentioned_users])\n",
    "            except Exception as e:\n",
    "                print(f\"El archivo presenta lineas con errores\")\n",
    "    # Se actualiza el contador\n",
    "    contador.update(data)\n",
    "```\n",
    "\n",
    "B. Para el ejercicio 2, buscar alternativas con base en la utilización de expresiones regulares. En el desarrollo se realizaron pruebas con expresiones regulares, pero no fueron del todo satisfactorias. Esto ocurrió debido a que las expresiones regulares que se utilizaron no consideraban emojis compuestos (Zero Width Joiner). En relación a los tiempos de ejecución, las expresiones regulares presentaron un mejor desempeño. Otra mejora adicional corresponde a la limpieza previa de los tonos de piel para los emojis, de esta forma se logrará un conteo más preciso.\n",
    "\n",
    "C. Para las funciones que priorizan el tiempo de ejecución, queda pendiente realizar las pruebas con la carga completa del archivo por medio de *pandas*.\n",
    "\n",
    "D. Revisar opciones de paralelización al momento de la lectura de los datos iniciales. De la misma forma en que la utilización de *emot* demostró que la paralelización disminuyó los tiempos en el análisis de los emojis, es una opción buscar alguna forma similar para la lectura del archivo.\n",
    "\n",
    "E. Buscar una solución en *GCP*, mediante la utilización de *Cloud Storage* para el almacenamiento del archivo. A través de una *Cloud Function* se podría desencadenar un *pipeline*, ya sea mediante un trabajo en *Dataflow* para realizar el análisis de cada una de las preguntas, o utilizando *Cloud Run* para el procesamiento. Es importante tener en cuenta la volumetría de los datos para casos productivos y los costos asociados a la utilización de la infraestructura.\n",
    "\n",
    "## Configuración del Entorno de Pruebas\n",
    "\n",
    "### Hardware\n",
    "- **Procesador:** Apple M2 Pro\n",
    "- **Memoria RAM:** 16 GB DDR4\n",
    "- **Almacenamiento:** SSD 512 GB\n",
    "\n",
    "### Software\n",
    "- **Sistema Operativo:** macOS Sonoma 14.5 (23F79)\n",
    "- **Versión de Python:** 3.9.9\n",
    "- **Librerías:** \n",
    "  - memory-profiler 0.61.0\n",
    "  - jsonlines 4.0.0\n",
    "  - polars 1.0.0\n",
    "  - emot 3.1\n",
    "  - pandas 2.2.2\n",
    "- **Entorno de Ejecución:** Entorno virtual creado con `venv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
