{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LATAM Challenge Data Engineer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Descripci√≥n del caso\n",
    "\n",
    "El ejercicio de estudio del desaf√≠o consiste en el an√°lisis de datos provenientes de Twitter, actualmente X. El objetivo es rescatar informaci√≥n estad√≠stica de los tweets relacionados con las protestas de los granjeros en India. Este an√°lisis est√°n enfocados en dos m√©tricas: la utilizaci√≥n de memoria y el tiempo de cada una de las funciones que buscan responder a las preguntas planteadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Supuestos y consideraciones\n",
    "\n",
    "Se realiz√≥ una revisi√≥n inicial de los datos proporcionados para identificar la existencia de tweets duplicados o de aquellos en los que existe m√°s de una menci√≥n a la misma persona en el mismo tweet de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga inicial del archivo, los archivos siempre estaran en la ruta \"../data/<archivo>.json\"\n",
    "file_path = \"../data/farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import jsonlines\n",
    "\n",
    "data = []\n",
    "with jsonlines.open(file_path) as reader:\n",
    "    for obj in reader:\n",
    "        users = []\n",
    "        users_dedup = []\n",
    "        mentioned_users = obj.get('mentionedUsers', {})\n",
    "        if mentioned_users:\n",
    "            users.extend([item['username'] for item in mentioned_users])\n",
    "            users_dedup.extend(list(set(item['username'] for item in mentioned_users)))\n",
    "        tweet = {\n",
    "            'date': obj.get('date'),\n",
    "            'id': obj.get('id'),\n",
    "            'username': obj.get('user', {}).get('username'),\n",
    "            'mentionedUsers': users,\n",
    "            'users_dedup': users_dedup\n",
    "        }\n",
    "        data.append(tweet)\n",
    "df = pl.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_count = df.group_by('id').len()\n",
    "id_count = id_count.filter(pl.col('len')>1)\n",
    "len(id_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El total de registros duplicados para el dataframe por el id del tweet generado es cero para el archivo de estudio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La revisi√≥n de las m√∫ltiples menciones en el mismo tweet se verific√≥ de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mensiones_duplicadas = df.filter(pl.col('mentionedUsers').len() != pl.col('users_dedup').len())\n",
    "len(mensiones_duplicadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supuestos generales\n",
    "\n",
    "1. Los archivos para su ejecuci√≥n se encuentran en la ruta: \"../data/farmers-protest-tweets-2021-2-4.json\"\n",
    "2. Los emojis con variaciones de tono de piel ser√°n tratados como emojis distintos.\n",
    "3. Los datos que se extraen desde Twitter son √∫nicos y no tienen duplicados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explicaci√≥n de las funciones implementadas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1\n",
    "Las top 10 fechas donde hay m√°s tweets. Mencionar el usuario (username) que m√°s publicaciones tiene por cada uno de esos d√≠as."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizaci√≥n de tiempo\n",
    "\n",
    "Para responder a este requerimiento se opt√≥ por utilizar la librer√≠a *polars* de python, con la cual se busca cargar la informaci√≥n a procesar en memoria para posteriormente procesarla seg√∫n las necesidades del caso.\n",
    "\n",
    "```Python\n",
    "with jsonlines.open(file_path) as reader:\n",
    "        for obj in reader:\n",
    "            # Se rescata solo los campos que se analizaran\n",
    "            filter_obj = {\n",
    "                'date': obj.get('date'),\n",
    "                'username': obj.get('user', {}).get('username')\n",
    "            }\n",
    "            data.append(filter_obj)\n",
    "```\n",
    "\n",
    "De la estructura de cada objeto json se obtiene la fecha y el username de qui√©n realiz√≥ el tweet.\n",
    "\n",
    "Luego se procesa con polars, primero para obtener las fechas con m√°s tweets:\n",
    "\n",
    "```Python\n",
    "    top_fechas =( df\n",
    "                    .group_by('date')\n",
    "                    .len()\n",
    "                    .sort('len',descending=True)\n",
    "                    .head(10)['date']\n",
    "                )\n",
    "```\n",
    "\n",
    "Luego se filtra el dataframe inicial por estas fechas:\n",
    "\n",
    "```Python\n",
    "result = (  df_filtrado.group_by(['date', 'username'])\n",
    "            .len() # Se cuenta para cada usuario por fecha \n",
    "            .sort(by=['date', 'len'], descending=[False, True]) # Se ordena por fecha desendente false y largo true\n",
    "            .group_by('date') # se agrupa por fechas\n",
    "            .agg(\n",
    "                    # Se agrega y se rescata le primer usuario por fecha\n",
    "                    pl.col('username').first()\n",
    "                )\n",
    "     )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "from q1_time import q1_time\n",
    "result = q1_time(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizaci√≥n de memoria\n",
    "\n",
    "Para responder a este requerimiento se opt√≥ por la lectura secuencial del archivo, por cada linea nueva que se procesa se rescatan las estad√≠sticas necesarias para el c√°lculo final.\n",
    "\n",
    "```Python\n",
    "with jsonlines.open(file_path) as reader:\n",
    "    for obj in reader:\n",
    "        # Se obtiene la fecha de cada uno de los registros\n",
    "        fecha_str = obj.get('date')[:10]\n",
    "        # Se castea de string a datetime.date\n",
    "        fecha = datetime.strptime(fecha_str, '%Y-%m-%d').date()\n",
    "        # Se actualiza el contador de fechas\n",
    "        fecha_counter[fecha] += 1\n",
    "        # Se actualiza el contador de usuarios por fechas\n",
    "        fecha_usuario_counter[fecha][obj.get('user', {}).get('username')] += 1\n",
    "```\n",
    "\n",
    "Se utiliza un  `fecha_usuario_counter = defaultdict(Counter)` para almacenar los totales por cada fecha y usuario.\n",
    "\n",
    "Luego se itera por cada una de las fechas.\n",
    "\n",
    "```Python\n",
    "for fecha in top_fechas:\n",
    "    usuarios = fecha_usuario_counter[fecha[0]]\n",
    "    usuario_mas_repetido = usuarios.most_common(1)[0][0]\n",
    "    result.append((fecha[0], usuario_mas_repetido))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "from q1_memory import q1_memory\n",
    "result = q1_memory(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaci√≥n de tiempo y uso de memoria para cada una de las funciones\n",
    "#### Tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.199416044"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from io import StringIO\n",
    "from q1_time import q1_time\n",
    "from q1_memory import q1_memory\n",
    "\n",
    "output_stream = StringIO()\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "q1_time(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "stats = pstats.Stats(profiler)\n",
    "stats.stream = output_stream\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('time')\n",
    "stats.print_stats()\n",
    "\n",
    "# Obtener el tottime final\n",
    "tiempo_total_q1_time = stats.total_tt\n",
    "tiempo_total_q1_time\n",
    "\n",
    "output_stream = StringIO()\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "q1_memory(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "stats = pstats.Stats(profiler)\n",
    "stats.stream = output_stream\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('time')\n",
    "stats.print_stats()\n",
    "# Obtener el tottime final\n",
    "tiempo_total_q1_memory = stats.total_tt\n",
    "tiempo_total_q1_memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La funci√≥n que prioriza el tiempo tiene un consumo de: 2.4117 segundos, \n",
      "mientras que la funci√≥n que prioriza el uso de memoria tiene un consumo de: 3.1994 segundos.\n",
      "Lo que representa una mejora de 28.0789%.\n"
     ]
    }
   ],
   "source": [
    "print(f'La funci√≥n que prioriza el tiempo tiene un consumo de: {tiempo_total_q1_time:.4f} segundos, \\nmientras que la funci√≥n que prioriza el uso de memoria tiene un consumo de: {tiempo_total_q1_memory:.4f} segundos.')\n",
    "diferencia_porcentual = (abs(tiempo_total_q1_time - tiempo_total_q1_memory)/((tiempo_total_q1_time + tiempo_total_q1_memory)/2)) * 100\n",
    "print(f'Lo que representa una mejora de {diferencia_porcentual:.4f}%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/hvera/Dev/DE_LATAM_challenge/LATAM-Data-Engineer-Challenge/src/q1_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     8    326.0 MiB    326.0 MiB           1   def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "     9                                             \"\"\"\n",
      "    10                                             Funcion que lee un archivo JSONL y encuentra las 10 fechas con mayor \n",
      "    11                                             cantidad de tweets, para cada una de estas fechas entrega el usuario \n",
      "    12                                             con mayor cantidad de tweets.\n",
      "    13                                         \n",
      "    14                                             Args:\n",
      "    15                                                 file_path (str): Ruta del archivo JSONL que contiene los tweets para \n",
      "    16                                                 analizar.\n",
      "    17                                         \n",
      "    18                                             Returns:\n",
      "    19                                                 List[Tuple[datetime.date, str]]: Lista de tuplas, donde el primer \n",
      "    20                                                 elemento corresponde a la fecha y el segundo elemento al nombre del \n",
      "    21                                                 usuario.\n",
      "    22                                             \"\"\"\n",
      "    23    326.0 MiB      0.0 MiB           1       result = []\n",
      "    24                                             # Contador para las fechas\n",
      "    25    326.0 MiB      0.0 MiB           1       fecha_counter = Counter()\n",
      "    26    326.0 MiB      0.0 MiB           1       fecha_usuario_counter = defaultdict(Counter)\n",
      "    27                                             # Lectura de archivo JSONL, se lee linea por linea para para reducir el uso\n",
      "    28                                             # de memoria\n",
      "    29    326.0 MiB      0.0 MiB           1       with jsonlines.open(file_path) as reader:\n",
      "    30    326.6 MiB      0.1 MiB      117408           for obj in reader:\n",
      "    31                                                     # Se obtiene la fecha de cada uno de los registros\n",
      "    32    326.6 MiB      0.0 MiB      117407               fecha_str = obj.get('date')[:10]\n",
      "    33                                                     # Se castea de string a datetime.date\n",
      "    34    326.6 MiB      0.0 MiB      117407               fecha = datetime.strptime(fecha_str, '%Y-%m-%d').date()\n",
      "    35                                                     # Se actualiza el contador de fechas\n",
      "    36    326.6 MiB      0.0 MiB      117407               fecha_counter[fecha] += 1\n",
      "    37                                                     # Se actualiza el contador de usuarios por fechas\n",
      "    38    326.6 MiB      0.5 MiB      469628               fecha_usuario_counter[fecha][obj.get(\n",
      "    39    326.6 MiB      0.0 MiB      352221                   'user', {}).get('username')] += 1\n",
      "    40                                         \n",
      "    41                                             # El top 10 de elementos mas comunes del contador\n",
      "    42    326.6 MiB      0.0 MiB           1       top_fechas = fecha_counter.most_common(10)\n",
      "    43                                             # Se itera por cada una de las fechas con mayor cantidad de tweets\n",
      "    44    326.6 MiB      0.0 MiB          11       for fecha in top_fechas:\n",
      "    45    326.6 MiB      0.0 MiB          10           usuarios = fecha_usuario_counter[fecha[0]]\n",
      "    46    326.6 MiB      0.0 MiB          10           usuario_mas_repetido = usuarios.most_common(1)[0][0]\n",
      "    47    326.6 MiB      0.0 MiB          10           result.append((fecha[0], usuario_mas_repetido))\n",
      "    48                                         \n",
      "    49    326.6 MiB      0.0 MiB           1       return result"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "%mprun -f q1_memory q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total de memoria utilizada  326.6 MiB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/hvera/Dev/DE_LATAM_challenge/LATAM-Data-Engineer-Challenge/src/q1_time.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     8    326.6 MiB    326.6 MiB           1   def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "     9                                             \"\"\"\n",
      "    10                                             Funcion que lee un archivo JSONL y encuentra las 10 fechas con mayor \n",
      "    11                                             cantidad de tweets, para cada una de estas fechas entrega el usuario con \n",
      "    12                                             mayor cantidad de tweets, se prioriza el tiempo de ejecucion.\n",
      "    13                                             Para esto se carga toda la informacion en memoria antes de procesarla.\n",
      "    14                                         \n",
      "    15                                             Args:\n",
      "    16                                                 file_path (str): Ruta del archivo JSONL que contiene los tweets para \n",
      "    17                                                 analizar.\n",
      "    18                                         \n",
      "    19                                             Returns:\n",
      "    20                                                 List[Tuple[datetime.date, str]]: Lista de tuplas, donde el primer \n",
      "    21                                                 elemento corresponde a la fecha y el segundo elemento al nombre del \n",
      "    22                                                 usuario.\n",
      "    23                                             \"\"\"\n",
      "    24                                             # Lista que almacena la informacion en memoria linea por linea\n",
      "    25    326.6 MiB      0.0 MiB           1       data = []\n",
      "    26                                             # Lectura de archivo JSONL, se lee linea por linea\n",
      "    27    326.6 MiB      0.0 MiB           1       with jsonlines.open(file_path) as reader:\n",
      "    28    366.8 MiB     39.6 MiB      117408           for obj in reader:\n",
      "    29                                                     # Se rescata solo los campos que se analizaran\n",
      "    30    366.8 MiB      0.0 MiB      117407               filter_obj = {\n",
      "    31    366.8 MiB      0.0 MiB      117407                   'date': obj.get('date'),\n",
      "    32    366.8 MiB      0.0 MiB      117407                   'username': obj.get('user', {}).get('username')\n",
      "    33                                                     }\n",
      "    34    366.8 MiB      0.6 MiB      117407               data.append(filter_obj)\n",
      "    35                                             # creacion de dataframe\n",
      "    36    366.8 MiB      0.0 MiB           1       df = pl.DataFrame(data)\n",
      "    37                                             # Transformacion de la columna date de str a date\n",
      "    38    366.8 MiB      0.0 MiB           3       df = df.with_columns([pl.col('date').str.strptime(\n",
      "    39    366.8 MiB      0.0 MiB           2           pl.Date, \"%Y-%m-%dT%H:%M:%S%z\").alias('date')])\n",
      "    40                                         \n",
      "    41                                             # Se retornan las 10 fechas con mayor cantidad de tweets\n",
      "    42    366.8 MiB      0.0 MiB           5       top_fechas = (df\n",
      "    43    366.8 MiB      0.0 MiB           1                     .group_by('date')\n",
      "    44                                                           .len()\n",
      "    45    366.8 MiB      0.0 MiB           1                     .sort('len', descending=True)\n",
      "    46    366.8 MiB      0.0 MiB           2                     .head(10)['date']\n",
      "    47                                                           )\n",
      "    48                                             # Se filtra el dataset por estas fechas\n",
      "    49    366.8 MiB      0.0 MiB           1       df_filtrado = df.filter(pl.col('date').is_in(top_fechas))\n",
      "    50                                             # Se elimina el dataset original\n",
      "    51    366.8 MiB      0.0 MiB           1       del df\n",
      "    52                                             # Se procesa el dataset filtrado\n",
      "    53    368.4 MiB      1.6 MiB           4       result = (df_filtrado.group_by(['date', 'username'])\n",
      "    54                                                       .len()  # Se cuenta para cada usuario por fecha\n",
      "    55                                                       # Se ordena por fecha desendente false y largo true\n",
      "    56    367.7 MiB      0.0 MiB           1                 .sort(by=['date', 'len'], descending=[False, True])\n",
      "    57    368.4 MiB      0.0 MiB           1                 .group_by('date')  # se agrupa por fechas\n",
      "    58                                                       .agg(\n",
      "    59                                                 # Se agrega y se rescata le primer usuario por fecha\n",
      "    60    368.4 MiB      0.0 MiB           1           pl.col('username').first()\n",
      "    61                                             )\n",
      "    62                                             )\n",
      "    63                                             # El resultado se joinea con las fechas para mantener el orden original\n",
      "    64                                             # que consiste en las fechas con mas tweets\n",
      "    65    368.4 MiB      0.0 MiB           1       result = top_fechas.to_frame().join(result, on='date', how=\"left\")\n",
      "    66                                             # Se formatea el output para que sea consistente con la descripcion de \n",
      "    67                                             # la funcion\n",
      "    68    368.4 MiB      0.0 MiB          13       result = [tuple(row.values()) for row in result.to_dicts()]\n",
      "    69    368.4 MiB      0.0 MiB           1       return result"
     ]
    }
   ],
   "source": [
    "%mprun -f q1_time q1_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total de memoria utilizada  368.4 MiB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "Los top 10 emojis m√°s usados con su respectivo conteo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizaci√≥n de tiempo\n",
    "\n",
    "Para responder a este requerimiento se opt√≥ por utilizar la librer√≠a *pandas* de python, a diferencia del resto de implementaciones se carg√≥ todo el archivo en memoria para luego procesarlo.\n",
    "\n",
    "`df = pd.read_json(file_path, lines=True)`\n",
    "\n",
    "Luego utilizando la librer√≠a *emot* se utiliza su implementaci√≥n para la lectura con multiprocesador en la siguiente l√≠nea:\n",
    "\n",
    "`emojis = emot_obj.bulk_emoji(data)`\n",
    "\n",
    "Para luego continuar con el procesamiento y terminar contando con *Counter*.\n",
    "\n",
    "Como mejoras a este ejercicio se propone identificar emojis con cambio de tono de piel como un solo emoji, por ejemplo: üëçüèΩ y üëç, sean tratados como un solo emoji y no dos como est√° en la implementaci√≥n actual.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('üôè', 5049), ('üòÇ', 3072), ('üöú', 2972), ('üåæ', 2182), ('üáÆüá≥', 2086), ('‚ù§', 1779), ('ü§£', 1668), ('‚úä', 1651), ('üôèüèª', 1317), ('üíö', 1040)]\n"
     ]
    }
   ],
   "source": [
    "from q2_time import q2_time\n",
    "result = q2_time(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizaci√≥n de memoria\n",
    "\n",
    "Para responder a este requerimiento se opt√≥ por la lectura secuencial del archivo utilizando la librer√≠a *jsonlines*.\n",
    "\n",
    "`with jsonlines.open(file_path) as reader`\n",
    "\n",
    "Por cada una de las lineas procesadas se utiliza el m√©todo *emoji* que retorna un diccionario con los emojis y su ubicaci√≥n en el texto.\n",
    "\n",
    "`emojis = emot_obj.emoji(content)`\n",
    "\n",
    "Ejemplo de salida:\n",
    "\n",
    "` {'value': ['‚òÆ', 'üôÇ', '‚ù§'], 'location': [[14, 15], [16, 17], [18, 19]], 'mean': [':peace_symbol:',':slightly_smiling_face:', ':red_heart:'], 'flag': True}` \n",
    "\n",
    "De este resultado se utilza 'value' el que se agrega al contador:\n",
    "\n",
    "`emojis = [item for item in emojis['value']]`\n",
    "\n",
    "`contador.update(emojis)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('üôè', 5049), ('üòÇ', 3072), ('üöú', 2972), ('üåæ', 2182), ('üáÆüá≥', 2086), ('‚ù§', 1779), ('ü§£', 1668), ('‚úä', 1651), ('üôèüèª', 1317), ('üíö', 1040)]\n"
     ]
    }
   ],
   "source": [
    "from q2_memory import q2_memory\n",
    "result = q2_memory(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaci√≥n de tiempo y uso de memoria para cada una de las funciones\n",
    "#### Tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from io import StringIO\n",
    "from q2_time import q2_time\n",
    "from q2_memory import q2_memory\n",
    "\n",
    "output_stream = StringIO()\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "q2_time(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "stats = pstats.Stats(profiler)\n",
    "stats.stream = output_stream\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('time')\n",
    "stats.print_stats()\n",
    "\n",
    "# Obtener el tottime final\n",
    "tiempo_total_q2_time = stats.total_tt\n",
    "\n",
    "output_stream = StringIO()\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "q2_memory(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "stats = pstats.Stats(profiler)\n",
    "stats.stream = output_stream\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('time')\n",
    "stats.print_stats()\n",
    "# Obtener el tottime final\n",
    "tiempo_total_q2_memory = stats.total_tt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La funci√≥n que prioriza el tiempo tiene un consumo de: 8.3032 segundos, \n",
      "mientras que la funci√≥n que prioriza el uso de memoria tiene un consumo de: 19.6812 segundos.\n",
      "Lo que representa una mejora de 81.3168%.\n"
     ]
    }
   ],
   "source": [
    "print(f'La funci√≥n que prioriza el tiempo tiene un consumo de: {tiempo_total_q2_time:.4f} segundos, \\nmientras que la funci√≥n que prioriza el uso de memoria tiene un consumo de: {tiempo_total_q2_memory:.4f} segundos.')\n",
    "diferencia_porcentual = (abs(tiempo_total_q2_time - tiempo_total_q2_memory)/((tiempo_total_q2_time + tiempo_total_q2_memory)/2)) * 100\n",
    "print(f'Lo que representa una mejora de {diferencia_porcentual:.4f}%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/hvera/Dev/DE_LATAM_challenge/LATAM-Data-Engineer-Challenge/src/q2_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     8    532.2 MiB    532.2 MiB           1   def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
      "     9                                             \"\"\"\n",
      "    10                                             Funcion que lee un archivo JSONL y encuentra los 10 emojis mas usados, \n",
      "    11                                             priorizando el uso de memoria.\n",
      "    12                                         \n",
      "    13                                             Args:\n",
      "    14                                                 file_path (str): Ruta del archivo JSONL que contiene los tweets para\n",
      "    15                                                 analizar.\n",
      "    16                                         \n",
      "    17                                             Returns:\n",
      "    18                                                 List[Tuple[str, int]]: Lista de tuplas, donde el primer elemento \n",
      "    19                                                 corresponde al emoji y el segundo a la cantidad de veces que se utiliza.\n",
      "    20                                             \"\"\"\n",
      "    21                                             # Contador para los emojis\n",
      "    22    532.2 MiB      0.0 MiB           1       contador = Counter()\n",
      "    23                                             # Se genera un objeto emot.core.emot\n",
      "    24    532.0 MiB     -0.2 MiB           1       emot_obj = emot.core.emot()\n",
      "    25                                             # Lectura de archivo JSONL, se lee linea por linea para para reducir\n",
      "    26                                             # el uso de memoria\n",
      "    27    532.0 MiB      0.0 MiB           1       with jsonlines.open(file_path) as reader:\n",
      "    28    532.0 MiB      0.0 MiB      117408           for obj in reader:\n",
      "    29                                                     # Se obtiene el objeto content que es donde esta el cuerpo del tweet\n",
      "    30    532.0 MiB      0.0 MiB      117407               content = obj.get('content')\n",
      "    31                                                     # Se obtiene la lista de diccionarios de los emojis encontrados\n",
      "    32                                                     # en el texto\n",
      "    33    532.0 MiB      0.0 MiB      117407               emojis = emot_obj.emoji(content)\n",
      "    34    532.0 MiB      0.0 MiB      117407               if emojis['value']:\n",
      "    35                                                         # Si se encontraron emojis en el texto se almacena solo\n",
      "    36                                                         # los emojis\n",
      "    37    532.0 MiB      0.0 MiB       93534                   emojis = [item for item in emojis['value']]\n",
      "    38                                                         # Se actualiza el contador con la lista de emojis\n",
      "    39    532.0 MiB      0.0 MiB       16869                   contador.update(emojis)\n",
      "    40                                             # Se retorna el top 10 de emojis\n",
      "    41    532.0 MiB      0.0 MiB           1       return contador.most_common(10)"
     ]
    }
   ],
   "source": [
    "%mprun -f q2_memory q2_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total de memoria utilizada  532.0 MiB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/hvera/Dev/DE_LATAM_challenge/LATAM-Data-Engineer-Challenge/src/q2_time.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     9    532.0 MiB    532.0 MiB           1   def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
      "    10                                             \"\"\"\n",
      "    11                                             Funcion que lee un archivo JSONL y encuentra los 10 emojis mas usados, \n",
      "    12                                             priorizando el uso de memoria.\n",
      "    13                                         \n",
      "    14                                             Args:\n",
      "    15                                                 file_path (str): Ruta del archivo JSONL que contiene los tweets \n",
      "    16                                                 para analizar.\n",
      "    17                                         \n",
      "    18                                             Returns:\n",
      "    19                                                 List[Tuple[str, int]]: Lista de tuplas, donde el primer elemento \n",
      "    20                                                 corresponde al emoji y el segundo a la cantidad de veces que se utiliza.\n",
      "    21                                             \"\"\"\n",
      "    22                                             # Contador para los emojis\n",
      "    23    532.0 MiB      0.0 MiB           1       contador = Counter()\n",
      "    24                                             # Lectura de archivo JSONL, se carga todo en memoria con pandas\n",
      "    25   1967.3 MiB   1435.3 MiB           1       df = pd.read_json(file_path, lines=True)\n",
      "    26                                             # Se genera un objeto emot.core.emot\n",
      "    27   1967.3 MiB      0.0 MiB           1       emot_obj = emot.core.emot()\n",
      "    28                                             # Se genera una lista con todos los elementos del dataframe de la\n",
      "    29                                             # columna content.\n",
      "    30                                             # Esta columna es la que tiene la informacion del texto del tweet\n",
      "    31   1967.3 MiB      0.0 MiB           1       data = df['content'].tolist()\n",
      "    32                                             # Se utiliza el metodo bulk_emoji ya que utiliza multi procesamiento\n",
      "    33   2009.3 MiB     41.9 MiB           1       emojis = emot_obj.bulk_emoji(data)\n",
      "    34                                             # Se deja la lista aplana la lista de listas solamente cuando existen emojis\n",
      "    35   2009.3 MiB      0.0 MiB      151149       emojis = list(chain.from_iterable(item['value']\n",
      "    36   2009.3 MiB      0.0 MiB      117408                     for item in emojis if item['value']))\n",
      "    37                                             # Actualizo el contador\n",
      "    38   2009.3 MiB      0.0 MiB           1       contador.update(emojis)\n",
      "    39   2009.3 MiB      0.0 MiB           1       return contador.most_common(10)"
     ]
    }
   ],
   "source": [
    "%mprun -f q2_time q2_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total de memoria utilizada  2009.3 MiB. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3\n",
    "El top 10 hist√≥rico de usuarios (username) m√°s influyentes en funci√≥n del conteo de las menciones (@) que registra cada uno de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizaci√≥n de tiempo\n",
    "\n",
    "Para responder a este requerimiento se probaron varias formas: para la primera prueba se utiliz√≥ la misma aproximaci√≥n aplicada al ejercicio 1, con la combinaci√≥n de *polars* y *jsonlines*. Al momento de comparar esta soluci√≥n con aquella que optimiza memoria, no siempre se obtuvieron mejores resultados en cuanto a tiempo.\n",
    "\n",
    "La segund aproximaci√≥n para este ejercici√≥ se realiz√≥ con el uso de *pandas* y cargar el archivo completo en memoria para procesar la columna que tiene los usuarios mencionados. Esta soluci√≥n entreg√≥ peores tiempos en comparaci√≥n con la primera propuesta de soluci√≥n, por lo que se descart√≥.\n",
    "\n",
    "La opci√≥n por la que finalmente se opt√≥ fue una mezcla entre la soluci√≥n implementada para la optimizaci√≥n de memoria, con la diferencia que en esta se cargan todos los usuarios mencionados y luego se actualiza un contador.\n",
    "\n",
    "```Python\n",
    "with jsonlines.open(file_path) as reader:\n",
    "        for obj in reader:\n",
    "            # Se rescata solo el campo mentionedUsers\n",
    "            mentioned_users = obj.get('mentionedUsers', {})\n",
    "            # Si se tienen mensiones en el tweet\n",
    "            if mentioned_users:\n",
    "                # Se extraen todos los usuarios mensionados\n",
    "                data.extend([item['username'] for item in mentioned_users])\n",
    "    # Se actualiza el contador\n",
    "    contador.update(data)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n"
     ]
    }
   ],
   "source": [
    "from q3_time import q3_time\n",
    "result = q3_time(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizaci√≥n de memoria\n",
    "\n",
    "Para responder a este requerimiento se opt√≥ por la lectura secuencial del archivo, al igual que en la implementaci√≥n del ejercicio 1 por cada l√≠nea nueva que se procesa se rescatan las l√≠nea necesarias para el c√°lculo final.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n"
     ]
    }
   ],
   "source": [
    "from q3_memory import q3_memory\n",
    "result = q3_memory(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaci√≥n de tiempo y uso de memoria para cada una de las funciones\n",
    "#### Tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from io import StringIO\n",
    "from q3_time import q3_time\n",
    "from q3_memory import q3_memory\n",
    "\n",
    "output_stream = StringIO()\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "q3_time(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "stats = pstats.Stats(profiler)\n",
    "stats.stream = output_stream\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('time')\n",
    "stats.print_stats()\n",
    "\n",
    "# Obtener el tottime final\n",
    "tiempo_total_q3_time = stats.total_tt\n",
    "\n",
    "output_stream = StringIO()\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "q3_memory(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "stats = pstats.Stats(profiler)\n",
    "stats.stream = output_stream\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('time')\n",
    "stats.print_stats()\n",
    "# Obtener el tottime final\n",
    "tiempo_total_q3_memory = stats.total_tt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La funci√≥n que prioriza el tiempo tiene un consumo de: 2.3312 segundos, \n",
      "mientras que la funci√≥n que prioriza el uso de memoria tiene un consumo de: 2.3320 segundos.\n",
      "Lo que representra una mejora de 0.0345%.\n"
     ]
    }
   ],
   "source": [
    "print(f'La funci√≥n que prioriza el tiempo tiene un consumo de: {tiempo_total_q3_time:.4f} segundos, \\nmientras que la funci√≥n que prioriza el uso de memoria tiene un consumo de: {tiempo_total_q3_memory:.4f} segundos.')\n",
    "diferencia_porcentual = (abs(tiempo_total_q3_time - tiempo_total_q3_memory)/((tiempo_total_q3_time + tiempo_total_q3_memory)/2)) * 100\n",
    "print(f'Lo que representra una mejora de {diferencia_porcentual:.4f}%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/hvera/Dev/DE_LATAM_challenge/LATAM-Data-Engineer-Challenge/src/q3_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     7    528.4 MiB    528.4 MiB           1   def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
      "     8                                             \"\"\"\n",
      "     9                                             Funcion que lee un archivo JSONL y encuentra los 10 usuarios con mayor\n",
      "    10                                             numero de menciones.\n",
      "    11                                             \n",
      "    12                                             Args:\n",
      "    13                                                 file_path (str): Ruta del archivo JSONL que contiene los tweets \n",
      "    14                                                 para analizar.\n",
      "    15                                             \n",
      "    16                                             Returns:\n",
      "    17                                                 List[Tuple[str, int]]: Lista de tuplas, donde el primer elemento \n",
      "    18                                                 corresponde al nombre de usuario y el segundo a la cantidad de menciones.\n",
      "    19                                             \"\"\"\n",
      "    20                                             # Contador para los usuarios\n",
      "    21    528.4 MiB      0.0 MiB           1       contador = Counter()\n",
      "    22                                             # Lectura de archivo JSONL, se lee linea por linea para para reducir\n",
      "    23                                             # el uso de memoria\n",
      "    24    528.4 MiB      0.0 MiB           1       with jsonlines.open(file_path) as reader:\n",
      "    25    528.4 MiB      0.0 MiB      117408           for obj in reader:\n",
      "    26                                                     # Se rescata solo el campo mentionedUsers\n",
      "    27    528.4 MiB      0.0 MiB      117407               mentioned_users = obj.get('mentionedUsers', {})\n",
      "    28    528.4 MiB      0.0 MiB      117407               if mentioned_users:\n",
      "    29                                                         # Si existen usuarios mencionados rescato la lista de username\n",
      "    30    528.4 MiB      0.0 MiB      217505                   mentioned_users = [item['username'] for item in mentioned_users]\n",
      "    31                                                         # Actualizo con contador de usuarios\n",
      "    32    528.4 MiB      0.0 MiB       38034                   contador.update(mentioned_users)\n",
      "    33    528.4 MiB      0.0 MiB           1       return contador.most_common(10)"
     ]
    }
   ],
   "source": [
    "%mprun -f q3_memory q3_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total de memoria utilizada  528.4 MiB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/hvera/Dev/DE_LATAM_challenge/LATAM-Data-Engineer-Challenge/src/q3_time.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     7    528.4 MiB    528.4 MiB           1   def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
      "     8                                             \"\"\"\n",
      "     9                                             Funcion que lee un archivo JSONL y encuentra los 10 usuarios con mayor \n",
      "    10                                             numero de menciones, prioriza el tiempo de ejecucion.\n",
      "    11                                         \n",
      "    12                                             Args:\n",
      "    13                                                 file_path (str): Ruta del archivo JSONL que contiene los tweets \n",
      "    14                                                 para analizar.\n",
      "    15                                         \n",
      "    16                                             Returns:\n",
      "    17                                                 List[Tuple[str, int]]: Lista de tuplas, donde el primer \n",
      "    18                                                 elemento corresponde al nombre de usuario y el segundo a la cantidad \n",
      "    19                                                 de menciones.\n",
      "    20                                             \"\"\"\n",
      "    21                                         \n",
      "    22                                             # Lista que almacena la informacion en memoria linea por linea\n",
      "    23    528.4 MiB      0.0 MiB           1       data = []\n",
      "    24    528.4 MiB      0.0 MiB           1       contador = Counter()\n",
      "    25                                             # Lectura de archivo JSONL, se lee linea por linea\n",
      "    26    528.4 MiB      0.0 MiB           1       with jsonlines.open(file_path) as reader:\n",
      "    27    528.4 MiB      0.0 MiB      117408           for obj in reader:\n",
      "    28                                                     # Se rescata solo el campo mentionedUsers\n",
      "    29    528.4 MiB      0.0 MiB      117407               mentioned_users = obj.get('mentionedUsers', {})\n",
      "    30                                                     # Si se tienen mensiones en el tweet\n",
      "    31    528.4 MiB      0.0 MiB      117407               if mentioned_users:\n",
      "    32                                                         # Se extraen todos los usuarios mensionados\n",
      "    33    528.4 MiB      0.0 MiB      217505                   data.extend([item['username'] for item in mentioned_users])\n",
      "    34                                             # Se actualiza el contador\n",
      "    35    528.4 MiB      0.0 MiB           1       contador.update(data)\n",
      "    36    528.4 MiB      0.0 MiB           1       return contador.most_common(10)"
     ]
    }
   ],
   "source": [
    "%mprun -f q3_time q3_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total de memoria utilizada  528.4 MiB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notas Adicionales \n",
    "\n",
    "En pruebas realizadas fuera del contexto del notebook los resultados generales para cada una de las funciones implementadas son los siguientes:\n",
    "1. Ejercicio 1\n",
    "\n",
    "| M√©trica   | q1_time       | q1_memory      | Diff %   |\n",
    "|-----------|---------------|--------------- |----------|\n",
    "| Time      | 2.401 seconds | 3.150 seconds  | 26.986       |\n",
    "| Memory    | 100.0 MiB     | 26.4 MiB      | 116.456       |\n",
    "\n",
    "\n",
    "2. Ejercicio 2\n",
    "\n",
    "| M√©trica   | q2_time       | q2_memory      | Diff %|\n",
    "|-----------|---------------|----------------|---------|\n",
    "| Time      | 9.249 seconds | 19.624 seconds | 71.866      |\n",
    "| Memory    | 1660.4 MiB    | 26.2 MiB       | 193.786      |\n",
    "\n",
    "\n",
    "3. Ejercicio 3\n",
    "\n",
    "| M√©trica   | q3_time       | q3_memory      | Diff %   |\n",
    "|-----------|---------------|--------------- |----------|\n",
    "| Time      | 2.257 seconds | 2.621 seconds  | 14.924       |\n",
    "| Memory    | 29.0 MiB      | 22.1 MiB       | 27.006      |\n",
    "\n",
    "\n",
    "## Mejoras\n",
    "\n",
    "Para las funciones que se desarrollaron se podr√≠an realizar las siguientes mejoras:\n",
    "\n",
    "A. Al momento de cargar el archivo l√≠nea por l√≠nea, revisar si la l√≠nea que se est√° cargando corresponde a un objeto JSON.\n",
    "\n",
    "```Python\n",
    "with jsonlines.open(file_path) as reader:\n",
    "        for obj in reader:\n",
    "            # Se rescata solo el campo mentionedUsers\n",
    "            try:\n",
    "                mentioned_users = obj.get('mentionedUsers', {})\n",
    "            # Si se tienen mensiones en el tweet\n",
    "                if mentioned_users:\n",
    "                # Se extraen todos los usuarios mensionados\n",
    "                    data.extend([item['username'] for item in mentioned_users])\n",
    "            except Exception as e:\n",
    "                print(f\"El archivo presenta lineas con errores\")\n",
    "    # Se actualiza el contador\n",
    "    contador.update(data)\n",
    "```\n",
    "\n",
    "B. Para el ejercicio 2, buscar alternativas con base en la utilizaci√≥n de expresiones regulares. En el desarrollo se realizaron pruebas con expresiones regulares, pero no fueron del todo satisfactorias. Esto ocurri√≥ debido a que las expresiones regulares que se utilizaron no consideraban emojis compuestos (Zero Width Joiner). En relaci√≥n a los tiempos de ejecuci√≥n, las expresiones regulares presentaron un mejor desempe√±o. Otra mejora adicional corresponde a la limpieza previa de los tonos de piel para los emojis, de esta forma se lograr√° un conteo m√°s preciso.\n",
    "\n",
    "C. Para las funciones que priorizan el tiempo de ejecuci√≥n, queda pendiente realizar las pruebas con la carga completa del archivo por medio de *pandas*.\n",
    "\n",
    "D. Revisar opciones de paralelizaci√≥n al momento de la lectura de los datos iniciales. De la misma forma en que la utilizaci√≥n de *emot* demostr√≥ que la paralelizaci√≥n disminuy√≥ los tiempos en el an√°lisis de los emojis, es una opci√≥n buscar alguna forma similar para la lectura del archivo.\n",
    "\n",
    "E. Buscar una soluci√≥n en *GCP*, mediante la utilizaci√≥n de *Cloud Storage* para el almacenamiento del archivo. A trav√©s de una *Cloud Function* se podr√≠a desencadenar un *pipeline*, ya sea mediante un trabajo en *Dataflow* para realizar el an√°lisis de cada una de las preguntas, o utilizando *Cloud Run* para el procesamiento. Es importante tener en cuenta la volumetr√≠a de los datos para casos productivos y los costos asociados a la utilizaci√≥n de la infraestructura.\n",
    "\n",
    "## Configuraci√≥n del Entorno de Pruebas\n",
    "\n",
    "### Hardware\n",
    "- **Procesador:** Apple M2 Pro\n",
    "- **Memoria RAM:** 16 GB DDR4\n",
    "- **Almacenamiento:** SSD 512 GB\n",
    "\n",
    "### Software\n",
    "- **Sistema Operativo:** macOS Sonoma 14.5 (23F79)\n",
    "- **Versi√≥n de Python:** 3.9.9\n",
    "- **Librer√≠as:** \n",
    "  - memory-profiler 0.61.0\n",
    "  - jsonlines 4.0.0\n",
    "  - polars 1.0.0\n",
    "  - emot 3.1\n",
    "  - pandas 2.2.2\n",
    "- **Entorno de Ejecuci√≥n:** Entorno virtual creado con `venv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
